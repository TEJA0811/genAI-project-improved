Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7299816824418297
Similarity between query and document 0: 0.7299816824418297
Similarity between query and document 0: 0.7299816824418297
Similarity between query and document 1: 0.7223017996925757
Similarity between query and document 1: 0.7223017996925757
Similarity between query and document 1: 0.7223017996925757
Similarity between query and document 2: 0.7084424507535374
Similarity between query and document 2: 0.7084424507535374
Similarity between query and document 2: 0.7084424507535374
Similarity between query and document 3: 0.7864566031444422
Similarity between query and document 3: 0.7864566031444422
Similarity between query and document 3: 0.7864566031444422
Similarity between query and document 4: 0.7188514530645304
Similarity between query and document 4: 0.7188514530645304
Similarity between query and document 4: 0.7188514530645304
Similarity between query and document 5: 0.712497776330355
Similarity between query and document 5: 0.712497776330355
Similarity between query and document 5: 0.712497776330355
Similarity between query and document 6: 0.7104522390224963
Similarity between query and document 6: 0.7104522390224963
Similarity between query and document 6: 0.7104522390224963
Similarity between query and document 10: 0.7103211745291189
Similarity between query and document 10: 0.7103211745291189
Similarity between query and document 10: 0.7103211745291189
Similarity between query and document 11: 0.7018534151561432
Similarity between query and document 11: 0.7018534151561432
Similarity between query and document 11: 0.7018534151561432
Similarity between query and document 12: 0.7168298404869899
Similarity between query and document 12: 0.7168298404869899
Similarity between query and document 12: 0.7168298404869899
Similarity between query and document 13: 0.7111050186055885
Similarity between query and document 13: 0.7111050186055885
Similarity between query and document 13: 0.7111050186055885
Similarity between query and document 18: 0.7153429412169867
Similarity between query and document 18: 0.7153429412169867
Similarity between query and document 18: 0.7153429412169867
Similarity between query and document 19: 0.7085968907445396
Similarity between query and document 19: 0.7085968907445396
Similarity between query and document 19: 0.7085968907445396
Similarity between query and document 20: 0.7129796584452729
Similarity between query and document 20: 0.7129796584452729
Similarity between query and document 20: 0.7129796584452729
Similarity between query and document 27: 0.7599482289096454
Similarity between query and document 27: 0.7599482289096454
Similarity between query and document 27: 0.7599482289096454
Similarity between query and document 29: 0.7252110042984226
Similarity between query and document 29: 0.7252110042984226
Similarity between query and document 29: 0.7252110042984226
Similarity between query and document 39: 0.7132967316634076
Similarity between query and document 39: 0.7132967316634076
Similarity between query and document 39: 0.7132967316634076
Similarity between query and document 41: 0.7059973785992955
Similarity between query and document 41: 0.7059973785992955
Similarity between query and document 41: 0.7059973785992955
Similarity between query and document 8: 0.7928489250993945
Similarity between query and document 8: 0.7928489250993945
Similarity between query and document 8: 0.7928489250993945
Similarity between query and document 14: 0.7040855843752993
Similarity between query and document 14: 0.7040855843752993
Similarity between query and document 14: 0.7040855843752993
Similarity between query and document 15: 0.684829127233056
Similarity between query and document 15: 0.684829127233056
Similarity between query and document 15: 0.684829127233056
Similarity between query and document 16: 0.7098285114879884
Similarity between query and document 16: 0.7098285114879884
Similarity between query and document 16: 0.7098285114879884
Similarity between query and document 17: 0.6968933008325153
Similarity between query and document 17: 0.6968933008325153
Similarity between query and document 17: 0.6968933008325153
Similarity between query and document 22: 0.7064483399051739
Similarity between query and document 22: 0.7064483399051739
Similarity between query and document 22: 0.7064483399051739
Similarity between query and document 23: 0.7102088191452717
Similarity between query and document 23: 0.7102088191452717
Similarity between query and document 23: 0.7102088191452717
Similarity between query and document 24: 0.7052372109959422
Similarity between query and document 24: 0.7052372109959422
Similarity between query and document 24: 0.7052372109959422
Similarity between query and document 34: 0.6951585218479127
Similarity between query and document 34: 0.6951585218479127
Similarity between query and document 34: 0.6951585218479127
Similarity between query and document 37: 0.6925338750520937
Similarity between query and document 37: 0.6925338750520937
Similarity between query and document 37: 0.6925338750520937
Similarity between query and document 38: 0.6951910667335429
Similarity between query and document 38: 0.6951910667335429
Similarity between query and document 38: 0.6951910667335429
Similarity between query and document 40: 0.7152133927990166
Similarity between query and document 40: 0.7152133927990166
Similarity between query and document 40: 0.7152133927990166
Similarity between query and document 36: 0.7159562421260959
Similarity between query and document 36: 0.7159562421260959
Similarity between query and document 36: 0.7159562421260959
Similarity between query and document 7: 0.7506925917433617
Similarity between query and document 7: 0.7506925917433617
Similarity between query and document 7: 0.7506925917433617
Similarity between query and document 9: 0.7246726063873392
Similarity between query and document 9: 0.7246726063873392
Similarity between query and document 9: 0.7246726063873392
Similarity between query and document 28: 0.7536613776055328
Similarity between query and document 28: 0.7536613776055328
Similarity between query and document 28: 0.7536613776055328
Similarity between query and document 25: 0.6856185286437623
Similarity between query and document 25: 0.6856185286437623
Similarity between query and document 25: 0.6856185286437623
Similarity between query and document 26: 0.6738355035995919
Similarity between query and document 26: 0.6738355035995919
Similarity between query and document 26: 0.6738355035995919
Similarity between query and document 21: 0.7285949499670447
Similarity between query and document 21: 0.7285949499670447
Similarity between query and document 21: 0.7285949499670447
Similarity between query and document 35: 0.6878458871831473
Similarity between query and document 35: 0.6878458871831473
Similarity between query and document 35: 0.6878458871831473
Similarity between query and document 30: 0.6881954411231823
Similarity between query and document 30: 0.6881954411231823
Similarity between query and document 30: 0.6881954411231823
Similarity between query and document 31: 0.7474973334038351
Similarity between query and document 31: 0.7474973334038351
Similarity between query and document 31: 0.7474973334038351
Similarity between query and document 33: 0.6735079138377263
Similarity between query and document 33: 0.6735079138377263
Similarity between query and document 33: 0.6735079138377263
Similarity between query and document 32: 0.7580802252989325
Similarity between query and document 32: 0.7580802252989325
Similarity between query and document 32: 0.7580802252989325
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7290098108660885
Similarity between query and document 0: 0.7290098108660885
Similarity between query and document 0: 0.7290098108660885
Similarity between query and document 1: 0.7192941397086161
Similarity between query and document 1: 0.7192941397086161
Similarity between query and document 1: 0.7192941397086161
Similarity between query and document 2: 0.726680863527299
Similarity between query and document 2: 0.726680863527299
Similarity between query and document 2: 0.726680863527299
Similarity between query and document 3: 0.7910508296641291
Similarity between query and document 3: 0.7910508296641291
Similarity between query and document 3: 0.7910508296641291
Similarity between query and document 4: 0.7218536044043236
Similarity between query and document 4: 0.7218536044043236
Similarity between query and document 4: 0.7218536044043236
Similarity between query and document 5: 0.7123444643660328
Similarity between query and document 5: 0.7123444643660328
Similarity between query and document 5: 0.7123444643660328
Similarity between query and document 6: 0.7215681734403053
Similarity between query and document 6: 0.7215681734403053
Similarity between query and document 6: 0.7215681734403053
Similarity between query and document 10: 0.7172952765352673
Similarity between query and document 10: 0.7172952765352673
Similarity between query and document 10: 0.7172952765352673
Similarity between query and document 11: 0.7059023629128647
Similarity between query and document 11: 0.7059023629128647
Similarity between query and document 11: 0.7059023629128647
Similarity between query and document 12: 0.7229668328111386
Similarity between query and document 12: 0.7229668328111386
Similarity between query and document 12: 0.7229668328111386
Similarity between query and document 13: 0.7167213056663888
Similarity between query and document 13: 0.7167213056663888
Similarity between query and document 13: 0.7167213056663888
Similarity between query and document 18: 0.7155050093684382
Similarity between query and document 18: 0.7155050093684382
Similarity between query and document 18: 0.7155050093684382
Similarity between query and document 19: 0.702677756268173
Similarity between query and document 19: 0.702677756268173
Similarity between query and document 19: 0.702677756268173
Similarity between query and document 20: 0.7151837901085526
Similarity between query and document 20: 0.7151837901085526
Similarity between query and document 20: 0.7151837901085526
Similarity between query and document 27: 0.7726765072268703
Similarity between query and document 27: 0.7726765072268703
Similarity between query and document 27: 0.7726765072268703
Similarity between query and document 29: 0.7358572950355314
Similarity between query and document 29: 0.7358572950355314
Similarity between query and document 29: 0.7358572950355314
Similarity between query and document 39: 0.7141939724221247
Similarity between query and document 39: 0.7141939724221247
Similarity between query and document 39: 0.7141939724221247
Similarity between query and document 41: 0.6976092337223299
Similarity between query and document 41: 0.6976092337223299
Similarity between query and document 41: 0.6976092337223299
Similarity between query and document 8: 0.8137412943430322
Similarity between query and document 8: 0.8137412943430322
Similarity between query and document 8: 0.8137412943430322
Similarity between query and document 14: 0.7240368349501072
Similarity between query and document 14: 0.7240368349501072
Similarity between query and document 14: 0.7240368349501072
Similarity between query and document 15: 0.6818049735359667
Similarity between query and document 15: 0.6818049735359667
Similarity between query and document 15: 0.6818049735359667
Similarity between query and document 16: 0.7144392396936252
Similarity between query and document 16: 0.7144392396936252
Similarity between query and document 16: 0.7144392396936252
Similarity between query and document 17: 0.7142291919211184
Similarity between query and document 17: 0.7142291919211184
Similarity between query and document 17: 0.7142291919211184
Similarity between query and document 22: 0.7200635563656934
Similarity between query and document 22: 0.7200635563656934
Similarity between query and document 22: 0.7200635563656934
Similarity between query and document 23: 0.7202855425331711
Similarity between query and document 23: 0.7202855425331711
Similarity between query and document 23: 0.7202855425331711
Similarity between query and document 24: 0.7131292507647531
Similarity between query and document 24: 0.7131292507647531
Similarity between query and document 24: 0.7131292507647531
Similarity between query and document 34: 0.6983144224084789
Similarity between query and document 34: 0.6983144224084789
Similarity between query and document 34: 0.6983144224084789
Similarity between query and document 37: 0.7156810858985845
Similarity between query and document 37: 0.7156810858985845
Similarity between query and document 37: 0.7156810858985845
Similarity between query and document 38: 0.711504579219389
Similarity between query and document 38: 0.711504579219389
Similarity between query and document 38: 0.711504579219389
Similarity between query and document 40: 0.7187284100223474
Similarity between query and document 40: 0.7187284100223474
Similarity between query and document 40: 0.7187284100223474
Similarity between query and document 36: 0.7246188690464953
Similarity between query and document 36: 0.7246188690464953
Similarity between query and document 36: 0.7246188690464953
Similarity between query and document 7: 0.7714253059240391
Similarity between query and document 7: 0.7714253059240391
Similarity between query and document 7: 0.7714253059240391
Similarity between query and document 9: 0.7345533482897297
Similarity between query and document 9: 0.7345533482897297
Similarity between query and document 9: 0.7345533482897297
Similarity between query and document 28: 0.7744332572679757
Similarity between query and document 28: 0.7744332572679757
Similarity between query and document 28: 0.7744332572679757
Similarity between query and document 25: 0.6979009035214105
Similarity between query and document 25: 0.6979009035214105
Similarity between query and document 25: 0.6979009035214105
Similarity between query and document 26: 0.6881603240807341
Similarity between query and document 26: 0.6881603240807341
Similarity between query and document 26: 0.6881603240807341
Similarity between query and document 21: 0.7314313489143345
Similarity between query and document 21: 0.7314313489143345
Similarity between query and document 21: 0.7314313489143345
Similarity between query and document 35: 0.6794895695475549
Similarity between query and document 35: 0.6794895695475549
Similarity between query and document 35: 0.6794895695475549
Similarity between query and document 30: 0.7041715606406057
Similarity between query and document 30: 0.7041715606406057
Similarity between query and document 30: 0.7041715606406057
Similarity between query and document 31: 0.7617502781771459
Similarity between query and document 31: 0.7617502781771459
Similarity between query and document 31: 0.7617502781771459
Similarity between query and document 33: 0.6938003451837627
Similarity between query and document 33: 0.6938003451837627
Similarity between query and document 33: 0.6938003451837627
Similarity between query and document 32: 0.7616208755879026
Similarity between query and document 32: 0.7616208755879026
Similarity between query and document 32: 0.7616208755879026
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.720276751177666
Similarity between query and document 0: 0.720276751177666
Similarity between query and document 0: 0.720276751177666
Similarity between query and document 1: 0.7154128088633241
Similarity between query and document 1: 0.7154128088633241
Similarity between query and document 1: 0.7154128088633241
Similarity between query and document 2: 0.7017574868993024
Similarity between query and document 2: 0.7017574868993024
Similarity between query and document 2: 0.7017574868993024
Similarity between query and document 3: 0.7756199784590659
Similarity between query and document 3: 0.7756199784590659
Similarity between query and document 3: 0.7756199784590659
Similarity between query and document 4: 0.706494886056382
Similarity between query and document 4: 0.706494886056382
Similarity between query and document 4: 0.706494886056382
Similarity between query and document 5: 0.7023704581475736
Similarity between query and document 5: 0.7023704581475736
Similarity between query and document 5: 0.7023704581475736
Similarity between query and document 6: 0.7022258509067368
Similarity between query and document 6: 0.7022258509067368
Similarity between query and document 6: 0.7022258509067368
Similarity between query and document 10: 0.7081009552078876
Similarity between query and document 10: 0.7081009552078876
Similarity between query and document 10: 0.7081009552078876
Similarity between query and document 11: 0.6944148772098333
Similarity between query and document 11: 0.6944148772098333
Similarity between query and document 11: 0.6944148772098333
Similarity between query and document 12: 0.7071263186654854
Similarity between query and document 12: 0.7071263186654854
Similarity between query and document 12: 0.7071263186654854
Similarity between query and document 13: 0.7044896321838612
Similarity between query and document 13: 0.7044896321838612
Similarity between query and document 13: 0.7044896321838612
Similarity between query and document 18: 0.704383316730937
Similarity between query and document 18: 0.704383316730937
Similarity between query and document 18: 0.704383316730937
Similarity between query and document 19: 0.6990027500409929
Similarity between query and document 19: 0.6990027500409929
Similarity between query and document 19: 0.6990027500409929
Similarity between query and document 20: 0.7159082019219342
Similarity between query and document 20: 0.7159082019219342
Similarity between query and document 20: 0.7159082019219342
Similarity between query and document 27: 0.7545995725865831
Similarity between query and document 27: 0.7545995725865831
Similarity between query and document 27: 0.7545995725865831
Similarity between query and document 29: 0.724245597372288
Similarity between query and document 29: 0.724245597372288
Similarity between query and document 29: 0.724245597372288
Similarity between query and document 39: 0.6990479291258581
Similarity between query and document 39: 0.6990479291258581
Similarity between query and document 39: 0.6990479291258581
Similarity between query and document 41: 0.6876803600254728
Similarity between query and document 41: 0.6876803600254728
Similarity between query and document 41: 0.6876803600254728
Similarity between query and document 8: 0.784487369881657
Similarity between query and document 8: 0.784487369881657
Similarity between query and document 8: 0.784487369881657
Similarity between query and document 14: 0.6978677994608744
Similarity between query and document 14: 0.6978677994608744
Similarity between query and document 14: 0.6978677994608744
Similarity between query and document 15: 0.6603866303896972
Similarity between query and document 15: 0.6603866303896972
Similarity between query and document 15: 0.6603866303896972
Similarity between query and document 16: 0.6910767878755144
Similarity between query and document 16: 0.6910767878755144
Similarity between query and document 16: 0.6910767878755144
Similarity between query and document 17: 0.6922224558919503
Similarity between query and document 17: 0.6922224558919503
Similarity between query and document 17: 0.6922224558919503
Similarity between query and document 22: 0.7014835797117828
Similarity between query and document 22: 0.7014835797117828
Similarity between query and document 22: 0.7014835797117828
Similarity between query and document 23: 0.706700590233521
Similarity between query and document 23: 0.706700590233521
Similarity between query and document 23: 0.706700590233521
Similarity between query and document 24: 0.6944135365357644
Similarity between query and document 24: 0.6944135365357644
Similarity between query and document 24: 0.6944135365357644
Similarity between query and document 34: 0.6886760489534325
Similarity between query and document 34: 0.6886760489534325
Similarity between query and document 34: 0.6886760489534325
Similarity between query and document 37: 0.6918139519144874
Similarity between query and document 37: 0.6918139519144874
Similarity between query and document 37: 0.6918139519144874
Similarity between query and document 38: 0.6892214995322885
Similarity between query and document 38: 0.6892214995322885
Similarity between query and document 38: 0.6892214995322885
Similarity between query and document 40: 0.7019876467983462
Similarity between query and document 40: 0.7019876467983462
Similarity between query and document 40: 0.7019876467983462
Similarity between query and document 36: 0.7103993215829912
Similarity between query and document 36: 0.7103993215829912
Similarity between query and document 36: 0.7103993215829912
Similarity between query and document 7: 0.7435744231208686
Similarity between query and document 7: 0.7435744231208686
Similarity between query and document 7: 0.7435744231208686
Similarity between query and document 9: 0.7216326483241483
Similarity between query and document 9: 0.7216326483241483
Similarity between query and document 9: 0.7216326483241483
Similarity between query and document 28: 0.7493302656286538
Similarity between query and document 28: 0.7493302656286538
Similarity between query and document 28: 0.7493302656286538
Similarity between query and document 25: 0.6772808594123878
Similarity between query and document 25: 0.6772808594123878
Similarity between query and document 25: 0.6772808594123878
Similarity between query and document 26: 0.6663260098134647
Similarity between query and document 26: 0.6663260098134647
Similarity between query and document 26: 0.6663260098134647
Similarity between query and document 21: 0.7203724637782886
Similarity between query and document 21: 0.7203724637782886
Similarity between query and document 21: 0.7203724637782886
Similarity between query and document 35: 0.6691607744094809
Similarity between query and document 35: 0.6691607744094809
Similarity between query and document 35: 0.6691607744094809
Similarity between query and document 30: 0.6935366183534658
Similarity between query and document 30: 0.6935366183534658
Similarity between query and document 30: 0.6935366183534658
Similarity between query and document 31: 0.7309330993457147
Similarity between query and document 31: 0.7309330993457147
Similarity between query and document 31: 0.7309330993457147
Similarity between query and document 33: 0.6813898754524259
Similarity between query and document 33: 0.6813898754524259
Similarity between query and document 33: 0.6813898754524259
Similarity between query and document 32: 0.7388432095099455
Similarity between query and document 32: 0.7388432095099455
Similarity between query and document 32: 0.7388432095099455
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7199961247407366
Similarity between query and document 0: 0.7199961247407366
Similarity between query and document 0: 0.7199961247407366
Similarity between query and document 1: 0.7071063135122357
Similarity between query and document 1: 0.7071063135122357
Similarity between query and document 1: 0.7071063135122357
Similarity between query and document 2: 0.7002776825852555
Similarity between query and document 2: 0.7002776825852555
Similarity between query and document 2: 0.7002776825852555
Similarity between query and document 3: 0.7788903197023345
Similarity between query and document 3: 0.7788903197023345
Similarity between query and document 3: 0.7788903197023345
Similarity between query and document 4: 0.7074042916232084
Similarity between query and document 4: 0.7074042916232084
Similarity between query and document 4: 0.7074042916232084
Similarity between query and document 5: 0.6973151261108733
Similarity between query and document 5: 0.6973151261108733
Similarity between query and document 5: 0.6973151261108733
Similarity between query and document 6: 0.7005754641799962
Similarity between query and document 6: 0.7005754641799962
Similarity between query and document 6: 0.7005754641799962
Similarity between query and document 10: 0.7052659083177696
Similarity between query and document 10: 0.7052659083177696
Similarity between query and document 10: 0.7052659083177696
Similarity between query and document 11: 0.7015867657585018
Similarity between query and document 11: 0.7015867657585018
Similarity between query and document 11: 0.7015867657585018
Similarity between query and document 12: 0.7095888787763878
Similarity between query and document 12: 0.7095888787763878
Similarity between query and document 12: 0.7095888787763878
Similarity between query and document 13: 0.6974981375263913
Similarity between query and document 13: 0.6974981375263913
Similarity between query and document 13: 0.6974981375263913
Similarity between query and document 18: 0.7070431982530259
Similarity between query and document 18: 0.7070431982530259
Similarity between query and document 18: 0.7070431982530259
Similarity between query and document 19: 0.6920537672840947
Similarity between query and document 19: 0.6920537672840947
Similarity between query and document 19: 0.6920537672840947
Similarity between query and document 20: 0.7041153916135331
Similarity between query and document 20: 0.7041153916135331
Similarity between query and document 20: 0.7041153916135331
Similarity between query and document 27: 0.7521378518771615
Similarity between query and document 27: 0.7521378518771615
Similarity between query and document 27: 0.7521378518771615
Similarity between query and document 29: 0.7128218838272284
Similarity between query and document 29: 0.7128218838272284
Similarity between query and document 29: 0.7128218838272284
Similarity between query and document 39: 0.6959485637080187
Similarity between query and document 39: 0.6959485637080187
Similarity between query and document 39: 0.6959485637080187
Similarity between query and document 41: 0.6865511493925056
Similarity between query and document 41: 0.6865511493925056
Similarity between query and document 41: 0.6865511493925056
Similarity between query and document 8: 0.7954328955951101
Similarity between query and document 8: 0.7954328955951101
Similarity between query and document 8: 0.7954328955951101
Similarity between query and document 14: 0.7037339770293006
Similarity between query and document 14: 0.7037339770293006
Similarity between query and document 14: 0.7037339770293006
Similarity between query and document 15: 0.6732115601600822
Similarity between query and document 15: 0.6732115601600822
Similarity between query and document 15: 0.6732115601600822
Similarity between query and document 16: 0.702701224278366
Similarity between query and document 16: 0.702701224278366
Similarity between query and document 16: 0.702701224278366
Similarity between query and document 17: 0.6893896756290423
Similarity between query and document 17: 0.6893896756290423
Similarity between query and document 17: 0.6893896756290423
Similarity between query and document 22: 0.7035536674212418
Similarity between query and document 22: 0.7035536674212418
Similarity between query and document 22: 0.7035536674212418
Similarity between query and document 23: 0.7053515079267899
Similarity between query and document 23: 0.7053515079267899
Similarity between query and document 23: 0.7053515079267899
Similarity between query and document 24: 0.6955542608188939
Similarity between query and document 24: 0.6955542608188939
Similarity between query and document 24: 0.6955542608188939
Similarity between query and document 34: 0.6844017380905151
Similarity between query and document 34: 0.6844017380905151
Similarity between query and document 34: 0.6844017380905151
Similarity between query and document 37: 0.6831344924963172
Similarity between query and document 37: 0.6831344924963172
Similarity between query and document 37: 0.6831344924963172
Similarity between query and document 38: 0.6938039064691731
Similarity between query and document 38: 0.6938039064691731
Similarity between query and document 38: 0.6938039064691731
Similarity between query and document 40: 0.7042791147314578
Similarity between query and document 40: 0.7042791147314578
Similarity between query and document 40: 0.7042791147314578
Similarity between query and document 36: 0.7149173162914859
Similarity between query and document 36: 0.7149173162914859
Similarity between query and document 36: 0.7149173162914859
Similarity between query and document 7: 0.7548289355429838
Similarity between query and document 7: 0.7548289355429838
Similarity between query and document 7: 0.7548289355429838
Similarity between query and document 9: 0.7222449443874195
Similarity between query and document 9: 0.7222449443874195
Similarity between query and document 9: 0.7222449443874195
Similarity between query and document 28: 0.7502430668394218
Similarity between query and document 28: 0.7502430668394218
Similarity between query and document 28: 0.7502430668394218
Similarity between query and document 25: 0.6898457508750659
Similarity between query and document 25: 0.6898457508750659
Similarity between query and document 25: 0.6898457508750659
Similarity between query and document 26: 0.6696574815177898
Similarity between query and document 26: 0.6696574815177898
Similarity between query and document 26: 0.6696574815177898
Similarity between query and document 21: 0.717634648347997
Similarity between query and document 21: 0.717634648347997
Similarity between query and document 21: 0.717634648347997
Similarity between query and document 35: 0.6693876408907672
Similarity between query and document 35: 0.6693876408907672
Similarity between query and document 35: 0.6693876408907672
Similarity between query and document 30: 0.6858871716813041
Similarity between query and document 30: 0.6858871716813041
Similarity between query and document 30: 0.6858871716813041
Similarity between query and document 31: 0.739156824449763
Similarity between query and document 31: 0.739156824449763
Similarity between query and document 31: 0.739156824449763
Similarity between query and document 33: 0.6722060794955288
Similarity between query and document 33: 0.6722060794955288
Similarity between query and document 33: 0.6722060794955288
Similarity between query and document 32: 0.7463482558137193
Similarity between query and document 32: 0.7463482558137193
Similarity between query and document 32: 0.7463482558137193
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7364233157217281
Similarity between query and document 0: 0.7364233157217281
Similarity between query and document 0: 0.7364233157217281
Similarity between query and document 1: 0.7275118889581906
Similarity between query and document 1: 0.7275118889581906
Similarity between query and document 1: 0.7275118889581906
Similarity between query and document 2: 0.7118623755707496
Similarity between query and document 2: 0.7118623755707496
Similarity between query and document 2: 0.7118623755707496
Similarity between query and document 3: 0.7799209710808296
Similarity between query and document 3: 0.7799209710808296
Similarity between query and document 3: 0.7799209710808296
Similarity between query and document 4: 0.7163715007392741
Similarity between query and document 4: 0.7163715007392741
Similarity between query and document 4: 0.7163715007392741
Similarity between query and document 5: 0.7165784599578573
Similarity between query and document 5: 0.7165784599578573
Similarity between query and document 5: 0.7165784599578573
Similarity between query and document 6: 0.715391558771672
Similarity between query and document 6: 0.715391558771672
Similarity between query and document 6: 0.715391558771672
Similarity between query and document 10: 0.7123719478923136
Similarity between query and document 10: 0.7123719478923136
Similarity between query and document 10: 0.7123719478923136
Similarity between query and document 11: 0.6999477331039035
Similarity between query and document 11: 0.6999477331039035
Similarity between query and document 11: 0.6999477331039035
Similarity between query and document 12: 0.7172192623555953
Similarity between query and document 12: 0.7172192623555953
Similarity between query and document 12: 0.7172192623555953
Similarity between query and document 13: 0.7095625003400207
Similarity between query and document 13: 0.7095625003400207
Similarity between query and document 13: 0.7095625003400207
Similarity between query and document 18: 0.7123345705936937
Similarity between query and document 18: 0.7123345705936937
Similarity between query and document 18: 0.7123345705936937
Similarity between query and document 19: 0.7112977941350456
Similarity between query and document 19: 0.7112977941350456
Similarity between query and document 19: 0.7112977941350456
Similarity between query and document 20: 0.7278930100457551
Similarity between query and document 20: 0.7278930100457551
Similarity between query and document 20: 0.7278930100457551
Similarity between query and document 27: 0.7556174373325762
Similarity between query and document 27: 0.7556174373325762
Similarity between query and document 27: 0.7556174373325762
Similarity between query and document 29: 0.7230329372252753
Similarity between query and document 29: 0.7230329372252753
Similarity between query and document 29: 0.7230329372252753
Similarity between query and document 39: 0.7007626045026665
Similarity between query and document 39: 0.7007626045026665
Similarity between query and document 39: 0.7007626045026665
Similarity between query and document 41: 0.7028730856468626
Similarity between query and document 41: 0.7028730856468626
Similarity between query and document 41: 0.7028730856468626
Similarity between query and document 8: 0.7794717303491624
Similarity between query and document 8: 0.7794717303491624
Similarity between query and document 8: 0.7794717303491624
Similarity between query and document 14: 0.7155612886587203
Similarity between query and document 14: 0.7155612886587203
Similarity between query and document 14: 0.7155612886587203
Similarity between query and document 15: 0.679079396620288
Similarity between query and document 15: 0.679079396620288
Similarity between query and document 15: 0.679079396620288
Similarity between query and document 16: 0.7132606227957228
Similarity between query and document 16: 0.7132606227957228
Similarity between query and document 16: 0.7132606227957228
Similarity between query and document 17: 0.7110360137492482
Similarity between query and document 17: 0.7110360137492482
Similarity between query and document 17: 0.7110360137492482
Similarity between query and document 22: 0.7037703897842247
Similarity between query and document 22: 0.7037703897842247
Similarity between query and document 22: 0.7037703897842247
Similarity between query and document 23: 0.7041827676239789
Similarity between query and document 23: 0.7041827676239789
Similarity between query and document 23: 0.7041827676239789
Similarity between query and document 24: 0.7073876099985055
Similarity between query and document 24: 0.7073876099985055
Similarity between query and document 24: 0.7073876099985055
Similarity between query and document 34: 0.6985352154601583
Similarity between query and document 34: 0.6985352154601583
Similarity between query and document 34: 0.6985352154601583
Similarity between query and document 37: 0.7012178884728832
Similarity between query and document 37: 0.7012178884728832
Similarity between query and document 37: 0.7012178884728832
Similarity between query and document 38: 0.694497490193165
Similarity between query and document 38: 0.694497490193165
Similarity between query and document 38: 0.694497490193165
Similarity between query and document 40: 0.7144977198551898
Similarity between query and document 40: 0.7144977198551898
Similarity between query and document 40: 0.7144977198551898
Similarity between query and document 36: 0.7193583627327244
Similarity between query and document 36: 0.7193583627327244
Similarity between query and document 36: 0.7193583627327244
Similarity between query and document 7: 0.7571088602805214
Similarity between query and document 7: 0.7571088602805214
Similarity between query and document 7: 0.7571088602805214
Similarity between query and document 9: 0.7282832176183739
Similarity between query and document 9: 0.7282832176183739
Similarity between query and document 9: 0.7282832176183739
Similarity between query and document 28: 0.7398144648163908
Similarity between query and document 28: 0.7398144648163908
Similarity between query and document 28: 0.7398144648163908
Similarity between query and document 25: 0.6827699696598336
Similarity between query and document 25: 0.6827699696598336
Similarity between query and document 25: 0.6827699696598336
Similarity between query and document 26: 0.6729886816842835
Similarity between query and document 26: 0.6729886816842835
Similarity between query and document 26: 0.6729886816842835
Similarity between query and document 21: 0.7280944440620223
Similarity between query and document 21: 0.7280944440620223
Similarity between query and document 21: 0.7280944440620223
Similarity between query and document 35: 0.6771999002545342
Similarity between query and document 35: 0.6771999002545342
Similarity between query and document 35: 0.6771999002545342
Similarity between query and document 30: 0.6811563137904042
Similarity between query and document 30: 0.6811563137904042
Similarity between query and document 30: 0.6811563137904042
Similarity between query and document 31: 0.7448065473381688
Similarity between query and document 31: 0.7448065473381688
Similarity between query and document 31: 0.7448065473381688
Similarity between query and document 33: 0.6730114919597994
Similarity between query and document 33: 0.6730114919597994
Similarity between query and document 33: 0.6730114919597994
Similarity between query and document 32: 0.752238768364597
Similarity between query and document 32: 0.752238768364597
Similarity between query and document 32: 0.752238768364597
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7394464767222046
Similarity between query and document 0: 0.7394464767222046
Similarity between query and document 0: 0.7394464767222046
Similarity between query and document 1: 0.7251535534289552
Similarity between query and document 1: 0.7251535534289552
Similarity between query and document 1: 0.7251535534289552
Similarity between query and document 2: 0.7116553769004186
Similarity between query and document 2: 0.7116553769004186
Similarity between query and document 2: 0.7116553769004186
Similarity between query and document 3: 0.7818645226651254
Similarity between query and document 3: 0.7818645226651254
Similarity between query and document 3: 0.7818645226651254
Similarity between query and document 4: 0.718383950469903
Similarity between query and document 4: 0.718383950469903
Similarity between query and document 4: 0.718383950469903
Similarity between query and document 5: 0.7181975165179341
Similarity between query and document 5: 0.7181975165179341
Similarity between query and document 5: 0.7181975165179341
Similarity between query and document 6: 0.7192966033736814
Similarity between query and document 6: 0.7192966033736814
Similarity between query and document 6: 0.7192966033736814
Similarity between query and document 10: 0.7158738987671954
Similarity between query and document 10: 0.7158738987671954
Similarity between query and document 10: 0.7158738987671954
Similarity between query and document 11: 0.7003384117629479
Similarity between query and document 11: 0.7003384117629479
Similarity between query and document 11: 0.7003384117629479
Similarity between query and document 12: 0.7116407031465343
Similarity between query and document 12: 0.7116407031465343
Similarity between query and document 12: 0.7116407031465343
Similarity between query and document 13: 0.7117886116551532
Similarity between query and document 13: 0.7117886116551532
Similarity between query and document 13: 0.7117886116551532
Similarity between query and document 18: 0.7127819109859526
Similarity between query and document 18: 0.7127819109859526
Similarity between query and document 18: 0.7127819109859526
Similarity between query and document 19: 0.7102122992953877
Similarity between query and document 19: 0.7102122992953877
Similarity between query and document 19: 0.7102122992953877
Similarity between query and document 20: 0.71177386273654
Similarity between query and document 20: 0.71177386273654
Similarity between query and document 20: 0.71177386273654
Similarity between query and document 27: 0.7486813628313218
Similarity between query and document 27: 0.7486813628313218
Similarity between query and document 27: 0.7486813628313218
Similarity between query and document 29: 0.7268479866570903
Similarity between query and document 29: 0.7268479866570903
Similarity between query and document 29: 0.7268479866570903
Similarity between query and document 39: 0.7068596796800266
Similarity between query and document 39: 0.7068596796800266
Similarity between query and document 39: 0.7068596796800266
Similarity between query and document 41: 0.7010142693660529
Similarity between query and document 41: 0.7010142693660529
Similarity between query and document 41: 0.7010142693660529
Similarity between query and document 8: 0.7799067719244002
Similarity between query and document 8: 0.7799067719244002
Similarity between query and document 8: 0.7799067719244002
Similarity between query and document 14: 0.7058742416123824
Similarity between query and document 14: 0.7058742416123824
Similarity between query and document 14: 0.7058742416123824
Similarity between query and document 15: 0.672885470918943
Similarity between query and document 15: 0.672885470918943
Similarity between query and document 15: 0.672885470918943
Similarity between query and document 16: 0.6990679069203776
Similarity between query and document 16: 0.6990679069203776
Similarity between query and document 16: 0.6990679069203776
Similarity between query and document 17: 0.7045653276288721
Similarity between query and document 17: 0.7045653276288721
Similarity between query and document 17: 0.7045653276288721
Similarity between query and document 22: 0.7045255654023803
Similarity between query and document 22: 0.7045255654023803
Similarity between query and document 22: 0.7045255654023803
Similarity between query and document 23: 0.7063163652818629
Similarity between query and document 23: 0.7063163652818629
Similarity between query and document 23: 0.7063163652818629
Similarity between query and document 24: 0.7053885254389342
Similarity between query and document 24: 0.7053885254389342
Similarity between query and document 24: 0.7053885254389342
Similarity between query and document 34: 0.6911312221519085
Similarity between query and document 34: 0.6911312221519085
Similarity between query and document 34: 0.6911312221519085
Similarity between query and document 37: 0.702118228207812
Similarity between query and document 37: 0.702118228207812
Similarity between query and document 37: 0.702118228207812
Similarity between query and document 38: 0.6927881040943434
Similarity between query and document 38: 0.6927881040943434
Similarity between query and document 38: 0.6927881040943434
Similarity between query and document 40: 0.7142953711636126
Similarity between query and document 40: 0.7142953711636126
Similarity between query and document 40: 0.7142953711636126
Similarity between query and document 36: 0.7141266095762947
Similarity between query and document 36: 0.7141266095762947
Similarity between query and document 36: 0.7141266095762947
Similarity between query and document 7: 0.752591272863485
Similarity between query and document 7: 0.752591272863485
Similarity between query and document 7: 0.752591272863485
Similarity between query and document 9: 0.7286265888552221
Similarity between query and document 9: 0.7286265888552221
Similarity between query and document 9: 0.7286265888552221
Similarity between query and document 28: 0.7421024808668113
Similarity between query and document 28: 0.7421024808668113
Similarity between query and document 28: 0.7421024808668113
Similarity between query and document 25: 0.6800524865981683
Similarity between query and document 25: 0.6800524865981683
Similarity between query and document 25: 0.6800524865981683
Similarity between query and document 26: 0.6670565036578952
Similarity between query and document 26: 0.6670565036578952
Similarity between query and document 26: 0.6670565036578952
Similarity between query and document 21: 0.7217494840033127
Similarity between query and document 21: 0.7217494840033127
Similarity between query and document 21: 0.7217494840033127
Similarity between query and document 35: 0.6812717606521504
Similarity between query and document 35: 0.6812717606521504
Similarity between query and document 35: 0.6812717606521504
Similarity between query and document 30: 0.6905486636236652
Similarity between query and document 30: 0.6905486636236652
Similarity between query and document 30: 0.6905486636236652
Similarity between query and document 31: 0.7398812609534572
Similarity between query and document 31: 0.7398812609534572
Similarity between query and document 31: 0.7398812609534572
Similarity between query and document 33: 0.6726230754204732
Similarity between query and document 33: 0.6726230754204732
Similarity between query and document 33: 0.6726230754204732
Similarity between query and document 32: 0.7558965427628035
Similarity between query and document 32: 0.7558965427628035
Similarity between query and document 32: 0.7558965427628035
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7272529304258806
Similarity between query and document 0: 0.7272529304258806
Similarity between query and document 0: 0.7272529304258806
Similarity between query and document 1: 0.7093767158637002
Similarity between query and document 1: 0.7093767158637002
Similarity between query and document 1: 0.7093767158637002
Similarity between query and document 2: 0.6989414025248494
Similarity between query and document 2: 0.6989414025248494
Similarity between query and document 2: 0.6989414025248494
Similarity between query and document 3: 0.7778645791647582
Similarity between query and document 3: 0.7778645791647582
Similarity between query and document 3: 0.7778645791647582
Similarity between query and document 4: 0.7129067021042922
Similarity between query and document 4: 0.7129067021042922
Similarity between query and document 4: 0.7129067021042922
Similarity between query and document 5: 0.7095502950239948
Similarity between query and document 5: 0.7095502950239948
Similarity between query and document 5: 0.7095502950239948
Similarity between query and document 6: 0.7129852589396607
Similarity between query and document 6: 0.7129852589396607
Similarity between query and document 6: 0.7129852589396607
Similarity between query and document 10: 0.7095866976393238
Similarity between query and document 10: 0.7095866976393238
Similarity between query and document 10: 0.7095866976393238
Similarity between query and document 11: 0.6896039550856752
Similarity between query and document 11: 0.6896039550856752
Similarity between query and document 11: 0.6896039550856752
Similarity between query and document 12: 0.704743995723672
Similarity between query and document 12: 0.704743995723672
Similarity between query and document 12: 0.704743995723672
Similarity between query and document 13: 0.7014686296182059
Similarity between query and document 13: 0.7014686296182059
Similarity between query and document 13: 0.7014686296182059
Similarity between query and document 18: 0.7028378165302904
Similarity between query and document 18: 0.7028378165302904
Similarity between query and document 18: 0.7028378165302904
Similarity between query and document 19: 0.6973504202561891
Similarity between query and document 19: 0.6973504202561891
Similarity between query and document 19: 0.6973504202561891
Similarity between query and document 20: 0.7071095481218062
Similarity between query and document 20: 0.7071095481218062
Similarity between query and document 20: 0.7071095481218062
Similarity between query and document 27: 0.742994196457525
Similarity between query and document 27: 0.742994196457525
Similarity between query and document 27: 0.742994196457525
Similarity between query and document 29: 0.7184857773207591
Similarity between query and document 29: 0.7184857773207591
Similarity between query and document 29: 0.7184857773207591
Similarity between query and document 39: 0.7040017689492309
Similarity between query and document 39: 0.7040017689492309
Similarity between query and document 39: 0.7040017689492309
Similarity between query and document 41: 0.6919346821202643
Similarity between query and document 41: 0.6919346821202643
Similarity between query and document 41: 0.6919346821202643
Similarity between query and document 8: 0.7697660227612246
Similarity between query and document 8: 0.7697660227612246
Similarity between query and document 8: 0.7697660227612246
Similarity between query and document 14: 0.6972353087148871
Similarity between query and document 14: 0.6972353087148871
Similarity between query and document 14: 0.6972353087148871
Similarity between query and document 15: 0.6690956190007076
Similarity between query and document 15: 0.6690956190007076
Similarity between query and document 15: 0.6690956190007076
Similarity between query and document 16: 0.7045729126702085
Similarity between query and document 16: 0.7045729126702085
Similarity between query and document 16: 0.7045729126702085
Similarity between query and document 17: 0.6968221727185374
Similarity between query and document 17: 0.6968221727185374
Similarity between query and document 17: 0.6968221727185374
Similarity between query and document 22: 0.6903640976460987
Similarity between query and document 22: 0.6903640976460987
Similarity between query and document 22: 0.6903640976460987
Similarity between query and document 23: 0.7000108681735059
Similarity between query and document 23: 0.7000108681735059
Similarity between query and document 23: 0.7000108681735059
Similarity between query and document 24: 0.703688099226796
Similarity between query and document 24: 0.703688099226796
Similarity between query and document 24: 0.703688099226796
Similarity between query and document 34: 0.6878524741908703
Similarity between query and document 34: 0.6878524741908703
Similarity between query and document 34: 0.6878524741908703
Similarity between query and document 37: 0.6904509602148181
Similarity between query and document 37: 0.6904509602148181
Similarity between query and document 37: 0.6904509602148181
Similarity between query and document 38: 0.6817342696908948
Similarity between query and document 38: 0.6817342696908948
Similarity between query and document 38: 0.6817342696908948
Similarity between query and document 40: 0.7156882058384015
Similarity between query and document 40: 0.7156882058384015
Similarity between query and document 40: 0.7156882058384015
Similarity between query and document 36: 0.6985852121861391
Similarity between query and document 36: 0.6985852121861391
Similarity between query and document 36: 0.6985852121861391
Similarity between query and document 7: 0.7395413572510585
Similarity between query and document 7: 0.7395413572510585
Similarity between query and document 7: 0.7395413572510585
Similarity between query and document 9: 0.7187131276558197
Similarity between query and document 9: 0.7187131276558197
Similarity between query and document 9: 0.7187131276558197
Similarity between query and document 28: 0.7366711746323285
Similarity between query and document 28: 0.7366711746323285
Similarity between query and document 28: 0.7366711746323285
Similarity between query and document 25: 0.6768634283450576
Similarity between query and document 25: 0.6768634283450576
Similarity between query and document 25: 0.6768634283450576
Similarity between query and document 26: 0.6630905156606832
Similarity between query and document 26: 0.6630905156606832
Similarity between query and document 26: 0.6630905156606832
Similarity between query and document 21: 0.7142023668506972
Similarity between query and document 21: 0.7142023668506972
Similarity between query and document 21: 0.7142023668506972
Similarity between query and document 35: 0.6755243679258855
Similarity between query and document 35: 0.6755243679258855
Similarity between query and document 35: 0.6755243679258855
Similarity between query and document 30: 0.6753753194226791
Similarity between query and document 30: 0.6753753194226791
Similarity between query and document 30: 0.6753753194226791
Similarity between query and document 31: 0.7342205739874696
Similarity between query and document 31: 0.7342205739874696
Similarity between query and document 31: 0.7342205739874696
Similarity between query and document 33: 0.6645633735210666
Similarity between query and document 33: 0.6645633735210666
Similarity between query and document 33: 0.6645633735210666
Similarity between query and document 32: 0.7581709120327462
Similarity between query and document 32: 0.7581709120327462
Similarity between query and document 32: 0.7581709120327462
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7365414858859191
Similarity between query and document 0: 0.7365414858859191
Similarity between query and document 0: 0.7365414858859191
Similarity between query and document 1: 0.7299087080926772
Similarity between query and document 1: 0.7299087080926772
Similarity between query and document 1: 0.7299087080926772
Similarity between query and document 2: 0.7159622286311073
Similarity between query and document 2: 0.7159622286311073
Similarity between query and document 2: 0.7159622286311073
Similarity between query and document 3: 0.7838363103413145
Similarity between query and document 3: 0.7838363103413145
Similarity between query and document 3: 0.7838363103413145
Similarity between query and document 4: 0.7197139782022326
Similarity between query and document 4: 0.7197139782022326
Similarity between query and document 4: 0.7197139782022326
Similarity between query and document 5: 0.7179719207535223
Similarity between query and document 5: 0.7179719207535223
Similarity between query and document 5: 0.7179719207535223
Similarity between query and document 6: 0.7180433257859241
Similarity between query and document 6: 0.7180433257859241
Similarity between query and document 6: 0.7180433257859241
Similarity between query and document 10: 0.7115836276525707
Similarity between query and document 10: 0.7115836276525707
Similarity between query and document 10: 0.7115836276525707
Similarity between query and document 11: 0.6979815250488021
Similarity between query and document 11: 0.6979815250488021
Similarity between query and document 11: 0.6979815250488021
Similarity between query and document 12: 0.7154441535064381
Similarity between query and document 12: 0.7154441535064381
Similarity between query and document 12: 0.7154441535064381
Similarity between query and document 13: 0.7104218585434829
Similarity between query and document 13: 0.7104218585434829
Similarity between query and document 13: 0.7104218585434829
Similarity between query and document 18: 0.7139937488564455
Similarity between query and document 18: 0.7139937488564455
Similarity between query and document 18: 0.7139937488564455
Similarity between query and document 19: 0.706426962658676
Similarity between query and document 19: 0.706426962658676
Similarity between query and document 19: 0.706426962658676
Similarity between query and document 20: 0.7244099307657268
Similarity between query and document 20: 0.7244099307657268
Similarity between query and document 20: 0.7244099307657268
Similarity between query and document 27: 0.760469565987452
Similarity between query and document 27: 0.760469565987452
Similarity between query and document 27: 0.760469565987452
Similarity between query and document 29: 0.7328753535657146
Similarity between query and document 29: 0.7328753535657146
Similarity between query and document 29: 0.7328753535657146
Similarity between query and document 39: 0.7101511163037065
Similarity between query and document 39: 0.7101511163037065
Similarity between query and document 39: 0.7101511163037065
Similarity between query and document 41: 0.7027741434692079
Similarity between query and document 41: 0.7027741434692079
Similarity between query and document 41: 0.7027741434692079
Similarity between query and document 8: 0.7892736552328223
Similarity between query and document 8: 0.7892736552328223
Similarity between query and document 8: 0.7892736552328223
Similarity between query and document 14: 0.7063552272736594
Similarity between query and document 14: 0.7063552272736594
Similarity between query and document 14: 0.7063552272736594
Similarity between query and document 15: 0.6767943123158009
Similarity between query and document 15: 0.6767943123158009
Similarity between query and document 15: 0.6767943123158009
Similarity between query and document 16: 0.7042702586032994
Similarity between query and document 16: 0.7042702586032994
Similarity between query and document 16: 0.7042702586032994
Similarity between query and document 17: 0.70513454703769
Similarity between query and document 17: 0.70513454703769
Similarity between query and document 17: 0.70513454703769
Similarity between query and document 22: 0.7038806443659282
Similarity between query and document 22: 0.7038806443659282
Similarity between query and document 22: 0.7038806443659282
Similarity between query and document 23: 0.7116997763997163
Similarity between query and document 23: 0.7116997763997163
Similarity between query and document 23: 0.7116997763997163
Similarity between query and document 24: 0.7087275258353576
Similarity between query and document 24: 0.7087275258353576
Similarity between query and document 24: 0.7087275258353576
Similarity between query and document 34: 0.6977888270777383
Similarity between query and document 34: 0.6977888270777383
Similarity between query and document 34: 0.6977888270777383
Similarity between query and document 37: 0.6946783369025785
Similarity between query and document 37: 0.6946783369025785
Similarity between query and document 37: 0.6946783369025785
Similarity between query and document 38: 0.6927040158606652
Similarity between query and document 38: 0.6927040158606652
Similarity between query and document 38: 0.6927040158606652
Similarity between query and document 40: 0.7181553637979319
Similarity between query and document 40: 0.7181553637979319
Similarity between query and document 40: 0.7181553637979319
Similarity between query and document 36: 0.7163720747324658
Similarity between query and document 36: 0.7163720747324658
Similarity between query and document 36: 0.7163720747324658
Similarity between query and document 7: 0.7530640843705193
Similarity between query and document 7: 0.7530640843705193
Similarity between query and document 7: 0.7530640843705193
Similarity between query and document 9: 0.7312384001319461
Similarity between query and document 9: 0.7312384001319461
Similarity between query and document 9: 0.7312384001319461
Similarity between query and document 28: 0.7479235658702119
Similarity between query and document 28: 0.7479235658702119
Similarity between query and document 28: 0.7479235658702119
Similarity between query and document 25: 0.6778484844390037
Similarity between query and document 25: 0.6778484844390037
Similarity between query and document 25: 0.6778484844390037
Similarity between query and document 26: 0.672788104219215
Similarity between query and document 26: 0.672788104219215
Similarity between query and document 26: 0.672788104219215
Similarity between query and document 21: 0.736177330680225
Similarity between query and document 21: 0.736177330680225
Similarity between query and document 21: 0.736177330680225
Similarity between query and document 35: 0.678010221672247
Similarity between query and document 35: 0.678010221672247
Similarity between query and document 35: 0.678010221672247
Similarity between query and document 30: 0.6841834591418509
Similarity between query and document 30: 0.6841834591418509
Similarity between query and document 30: 0.6841834591418509
Similarity between query and document 31: 0.7434244735186661
Similarity between query and document 31: 0.7434244735186661
Similarity between query and document 31: 0.7434244735186661
Similarity between query and document 33: 0.6778092371717501
Similarity between query and document 33: 0.6778092371717501
Similarity between query and document 33: 0.6778092371717501
Similarity between query and document 32: 0.7547929013833371
Similarity between query and document 32: 0.7547929013833371
Similarity between query and document 32: 0.7547929013833371
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7459105944459707
Similarity between query and document 0: 0.7459105944459707
Similarity between query and document 0: 0.7459105944459707
Similarity between query and document 0: 0.7459105944459707
Similarity between query and document 1: 0.7334905220928141
Similarity between query and document 1: 0.7334905220928141
Similarity between query and document 1: 0.7334905220928141
Similarity between query and document 1: 0.7334905220928141
Similarity between query and document 2: 0.728221192204311
Similarity between query and document 2: 0.728221192204311
Similarity between query and document 2: 0.728221192204311
Similarity between query and document 2: 0.728221192204311
Similarity between query and document 3: 0.7989028036046686
Similarity between query and document 3: 0.7989028036046686
Similarity between query and document 3: 0.7989028036046686
Similarity between query and document 3: 0.7989028036046686
Similarity between query and document 4: 0.7149060784626671
Similarity between query and document 4: 0.7149060784626671
Similarity between query and document 4: 0.7149060784626671
Similarity between query and document 4: 0.7149060784626671
Similarity between query and document 5: 0.7089336234989028
Similarity between query and document 5: 0.7089336234989028
Similarity between query and document 5: 0.7089336234989028
Similarity between query and document 5: 0.7089336234989028
Similarity between query and document 6: 0.7133991745358313
Similarity between query and document 6: 0.7133991745358313
Similarity between query and document 6: 0.7133991745358313
Similarity between query and document 6: 0.7133991745358313
Similarity between query and document 10: 0.7057347284906673
Similarity between query and document 10: 0.7057347284906673
Similarity between query and document 10: 0.7057347284906673
Similarity between query and document 10: 0.7057347284906673
Similarity between query and document 11: 0.689188325524419
Similarity between query and document 11: 0.689188325524419
Similarity between query and document 11: 0.689188325524419
Similarity between query and document 11: 0.689188325524419
Similarity between query and document 12: 0.7147651863348781
Similarity between query and document 12: 0.7147651863348781
Similarity between query and document 12: 0.7147651863348781
Similarity between query and document 12: 0.7147651863348781
Similarity between query and document 13: 0.6963483331972877
Similarity between query and document 13: 0.6963483331972877
Similarity between query and document 13: 0.6963483331972877
Similarity between query and document 13: 0.6963483331972877
Similarity between query and document 18: 0.7139810473988961
Similarity between query and document 18: 0.7139810473988961
Similarity between query and document 18: 0.7139810473988961
Similarity between query and document 18: 0.7139810473988961
Similarity between query and document 19: 0.6946577179143241
Similarity between query and document 19: 0.6946577179143241
Similarity between query and document 19: 0.6946577179143241
Similarity between query and document 19: 0.6946577179143241
Similarity between query and document 20: 0.7194542235482148
Similarity between query and document 20: 0.7194542235482148
Similarity between query and document 20: 0.7194542235482148
Similarity between query and document 20: 0.7194542235482148
Similarity between query and document 27: 0.769190456711005
Similarity between query and document 27: 0.769190456711005
Similarity between query and document 27: 0.769190456711005
Similarity between query and document 27: 0.769190456711005
Similarity between query and document 29: 0.7289281427150089
Similarity between query and document 29: 0.7289281427150089
Similarity between query and document 29: 0.7289281427150089
Similarity between query and document 29: 0.7289281427150089
Similarity between query and document 39: 0.7011696140114559
Similarity between query and document 39: 0.7011696140114559
Similarity between query and document 39: 0.7011696140114559
Similarity between query and document 39: 0.7011696140114559
Similarity between query and document 41: 0.698788117500807
Similarity between query and document 41: 0.698788117500807
Similarity between query and document 41: 0.698788117500807
Similarity between query and document 41: 0.698788117500807
Similarity between query and document 8: 0.8150684858121611
Similarity between query and document 8: 0.8150684858121611
Similarity between query and document 8: 0.8150684858121611
Similarity between query and document 8: 0.8150684858121611
Similarity between query and document 14: 0.7055183287719722
Similarity between query and document 14: 0.7055183287719722
Similarity between query and document 14: 0.7055183287719722
Similarity between query and document 14: 0.7055183287719722
Similarity between query and document 15: 0.6710075314868006
Similarity between query and document 15: 0.6710075314868006
Similarity between query and document 15: 0.6710075314868006
Similarity between query and document 15: 0.6710075314868006
Similarity between query and document 16: 0.6950153912943562
Similarity between query and document 16: 0.6950153912943562
Similarity between query and document 16: 0.6950153912943562
Similarity between query and document 16: 0.6950153912943562
Similarity between query and document 17: 0.7046353927997964
Similarity between query and document 17: 0.7046353927997964
Similarity between query and document 17: 0.7046353927997964
Similarity between query and document 17: 0.7046353927997964
Similarity between query and document 22: 0.6875683483370568
Similarity between query and document 22: 0.6875683483370568
Similarity between query and document 22: 0.6875683483370568
Similarity between query and document 22: 0.6875683483370568
Similarity between query and document 23: 0.7022459123096787
Similarity between query and document 23: 0.7022459123096787
Similarity between query and document 23: 0.7022459123096787
Similarity between query and document 23: 0.7022459123096787
Similarity between query and document 24: 0.6931578851817097
Similarity between query and document 24: 0.6931578851817097
Similarity between query and document 24: 0.6931578851817097
Similarity between query and document 24: 0.6931578851817097
Similarity between query and document 34: 0.6778692435696386
Similarity between query and document 34: 0.6778692435696386
Similarity between query and document 34: 0.6778692435696386
Similarity between query and document 34: 0.6778692435696386
Similarity between query and document 37: 0.7014527173781607
Similarity between query and document 37: 0.7014527173781607
Similarity between query and document 37: 0.7014527173781607
Similarity between query and document 37: 0.7014527173781607
Similarity between query and document 38: 0.6824998156810945
Similarity between query and document 38: 0.6824998156810945
Similarity between query and document 38: 0.6824998156810945
Similarity between query and document 38: 0.6824998156810945
Similarity between query and document 40: 0.7063495002732575
Similarity between query and document 40: 0.7063495002732575
Similarity between query and document 40: 0.7063495002732575
Similarity between query and document 40: 0.7063495002732575
Similarity between query and document 36: 0.6886679624354475
Similarity between query and document 36: 0.6886679624354475
Similarity between query and document 36: 0.6886679624354475
Similarity between query and document 36: 0.6886679624354475
Similarity between query and document 7: 0.7810524541760081
Similarity between query and document 7: 0.7810524541760081
Similarity between query and document 7: 0.7810524541760081
Similarity between query and document 7: 0.7810524541760081
Similarity between query and document 9: 0.7421185682855629
Similarity between query and document 9: 0.7421185682855629
Similarity between query and document 9: 0.7421185682855629
Similarity between query and document 9: 0.7421185682855629
Similarity between query and document 28: 0.7683099626162122
Similarity between query and document 28: 0.7683099626162122
Similarity between query and document 28: 0.7683099626162122
Similarity between query and document 28: 0.7683099626162122
Similarity between query and document 25: 0.6784302461805455
Similarity between query and document 25: 0.6784302461805455
Similarity between query and document 25: 0.6784302461805455
Similarity between query and document 25: 0.6784302461805455
Similarity between query and document 26: 0.6641950607704189
Similarity between query and document 26: 0.6641950607704189
Similarity between query and document 26: 0.6641950607704189
Similarity between query and document 26: 0.6641950607704189
Similarity between query and document 21: 0.7371453655856054
Similarity between query and document 21: 0.7371453655856054
Similarity between query and document 21: 0.7371453655856054
Similarity between query and document 21: 0.7371453655856054
Similarity between query and document 35: 0.679999690020552
Similarity between query and document 35: 0.679999690020552
Similarity between query and document 35: 0.679999690020552
Similarity between query and document 35: 0.679999690020552
Similarity between query and document 30: 0.6887173392731766
Similarity between query and document 30: 0.6887173392731766
Similarity between query and document 30: 0.6887173392731766
Similarity between query and document 30: 0.6887173392731766
Similarity between query and document 31: 0.746203516509034
Similarity between query and document 31: 0.746203516509034
Similarity between query and document 31: 0.746203516509034
Similarity between query and document 31: 0.746203516509034
Similarity between query and document 33: 0.6776382393818715
Similarity between query and document 33: 0.6776382393818715
Similarity between query and document 33: 0.6776382393818715
Similarity between query and document 33: 0.6776382393818715
Similarity between query and document 32: 0.7612786655092433
Similarity between query and document 32: 0.7612786655092433
Similarity between query and document 32: 0.7612786655092433
Similarity between query and document 32: 0.7612786655092433
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7446919515843958
Similarity between query and document 0: 0.7446919515843958
Similarity between query and document 0: 0.7446919515843958
Similarity between query and document 1: 0.7309859897510255
Similarity between query and document 1: 0.7309859897510255
Similarity between query and document 1: 0.7309859897510255
Similarity between query and document 2: 0.7286005369036478
Similarity between query and document 2: 0.7286005369036478
Similarity between query and document 2: 0.7286005369036478
Similarity between query and document 3: 0.7955654422874572
Similarity between query and document 3: 0.7955654422874572
Similarity between query and document 3: 0.7955654422874572
Similarity between query and document 4: 0.7161762345299341
Similarity between query and document 4: 0.7161762345299341
Similarity between query and document 4: 0.7161762345299341
Similarity between query and document 5: 0.7122733309968644
Similarity between query and document 5: 0.7122733309968644
Similarity between query and document 5: 0.7122733309968644
Similarity between query and document 6: 0.7141788703345237
Similarity between query and document 6: 0.7141788703345237
Similarity between query and document 6: 0.7141788703345237
Similarity between query and document 10: 0.7076832690984116
Similarity between query and document 10: 0.7076832690984116
Similarity between query and document 10: 0.7076832690984116
Similarity between query and document 11: 0.6964326697478376
Similarity between query and document 11: 0.6964326697478376
Similarity between query and document 11: 0.6964326697478376
Similarity between query and document 12: 0.7204883515576649
Similarity between query and document 12: 0.7204883515576649
Similarity between query and document 12: 0.7204883515576649
Similarity between query and document 13: 0.6997407651034718
Similarity between query and document 13: 0.6997407651034718
Similarity between query and document 13: 0.6997407651034718
Similarity between query and document 18: 0.7135330849740192
Similarity between query and document 18: 0.7135330849740192
Similarity between query and document 18: 0.7135330849740192
Similarity between query and document 19: 0.6956735734648045
Similarity between query and document 19: 0.6956735734648045
Similarity between query and document 19: 0.6956735734648045
Similarity between query and document 20: 0.7214337909464681
Similarity between query and document 20: 0.7214337909464681
Similarity between query and document 20: 0.7214337909464681
Similarity between query and document 27: 0.7722138726991876
Similarity between query and document 27: 0.7722138726991876
Similarity between query and document 27: 0.7722138726991876
Similarity between query and document 29: 0.7277693515322314
Similarity between query and document 29: 0.7277693515322314
Similarity between query and document 29: 0.7277693515322314
Similarity between query and document 39: 0.7000394184815775
Similarity between query and document 39: 0.7000394184815775
Similarity between query and document 39: 0.7000394184815775
Similarity between query and document 41: 0.7015291635561394
Similarity between query and document 41: 0.7015291635561394
Similarity between query and document 41: 0.7015291635561394
Similarity between query and document 8: 0.8181957609863191
Similarity between query and document 8: 0.8181957609863191
Similarity between query and document 8: 0.8181957609863191
Similarity between query and document 14: 0.7082678965435858
Similarity between query and document 14: 0.7082678965435858
Similarity between query and document 14: 0.7082678965435858
Similarity between query and document 15: 0.6833819043125975
Similarity between query and document 15: 0.6833819043125975
Similarity between query and document 15: 0.6833819043125975
Similarity between query and document 16: 0.6985212806889392
Similarity between query and document 16: 0.6985212806889392
Similarity between query and document 16: 0.6985212806889392
Similarity between query and document 17: 0.7008281516865081
Similarity between query and document 17: 0.7008281516865081
Similarity between query and document 17: 0.7008281516865081
Similarity between query and document 22: 0.6939421226857577
Similarity between query and document 22: 0.6939421226857577
Similarity between query and document 22: 0.6939421226857577
Similarity between query and document 23: 0.7046984630822717
Similarity between query and document 23: 0.7046984630822717
Similarity between query and document 23: 0.7046984630822717
Similarity between query and document 24: 0.6967789665769554
Similarity between query and document 24: 0.6967789665769554
Similarity between query and document 24: 0.6967789665769554
Similarity between query and document 34: 0.6841850831215285
Similarity between query and document 34: 0.6841850831215285
Similarity between query and document 34: 0.6841850831215285
Similarity between query and document 37: 0.6960929670349938
Similarity between query and document 37: 0.6960929670349938
Similarity between query and document 37: 0.6960929670349938
Similarity between query and document 38: 0.6905388142975972
Similarity between query and document 38: 0.6905388142975972
Similarity between query and document 38: 0.6905388142975972
Similarity between query and document 40: 0.7093485638196431
Similarity between query and document 40: 0.7093485638196431
Similarity between query and document 40: 0.7093485638196431
Similarity between query and document 36: 0.6961870182169827
Similarity between query and document 36: 0.6961870182169827
Similarity between query and document 36: 0.6961870182169827
Similarity between query and document 7: 0.7883438108031056
Similarity between query and document 7: 0.7883438108031056
Similarity between query and document 7: 0.7883438108031056
Similarity between query and document 9: 0.7417510489972343
Similarity between query and document 9: 0.7417510489972343
Similarity between query and document 9: 0.7417510489972343
Similarity between query and document 28: 0.7617711095954454
Similarity between query and document 28: 0.7617711095954454
Similarity between query and document 28: 0.7617711095954454
Similarity between query and document 25: 0.6757454504310854
Similarity between query and document 25: 0.6757454504310854
Similarity between query and document 25: 0.6757454504310854
Similarity between query and document 26: 0.6754920054301862
Similarity between query and document 26: 0.6754920054301862
Similarity between query and document 26: 0.6754920054301862
Similarity between query and document 21: 0.737173181040923
Similarity between query and document 21: 0.737173181040923
Similarity between query and document 21: 0.737173181040923
Similarity between query and document 35: 0.6845998959198184
Similarity between query and document 35: 0.6845998959198184
Similarity between query and document 35: 0.6845998959198184
Similarity between query and document 30: 0.6882480108821771
Similarity between query and document 30: 0.6882480108821771
Similarity between query and document 30: 0.6882480108821771
Similarity between query and document 31: 0.74970010496662
Similarity between query and document 31: 0.74970010496662
Similarity between query and document 31: 0.74970010496662
Similarity between query and document 33: 0.6778571122330874
Similarity between query and document 33: 0.6778571122330874
Similarity between query and document 33: 0.6778571122330874
Similarity between query and document 32: 0.75760996348564
Similarity between query and document 32: 0.75760996348564
Similarity between query and document 32: 0.75760996348564
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7447941278863935
Similarity between query and document 0: 0.7447941278863935
Similarity between query and document 0: 0.7447941278863935
Similarity between query and document 1: 0.7378312059494538
Similarity between query and document 1: 0.7378312059494538
Similarity between query and document 1: 0.7378312059494538
Similarity between query and document 2: 0.7341672387421229
Similarity between query and document 2: 0.7341672387421229
Similarity between query and document 2: 0.7341672387421229
Similarity between query and document 3: 0.8013288628409414
Similarity between query and document 3: 0.8013288628409414
Similarity between query and document 3: 0.8013288628409414
Similarity between query and document 4: 0.7115195599636228
Similarity between query and document 4: 0.7115195599636228
Similarity between query and document 4: 0.7115195599636228
Similarity between query and document 5: 0.7042364994028255
Similarity between query and document 5: 0.7042364994028255
Similarity between query and document 5: 0.7042364994028255
Similarity between query and document 6: 0.7041675644133006
Similarity between query and document 6: 0.7041675644133006
Similarity between query and document 6: 0.7041675644133006
Similarity between query and document 10: 0.6973867204759283
Similarity between query and document 10: 0.6973867204759283
Similarity between query and document 10: 0.6973867204759283
Similarity between query and document 11: 0.6905688470423145
Similarity between query and document 11: 0.6905688470423145
Similarity between query and document 11: 0.6905688470423145
Similarity between query and document 12: 0.7100409879022886
Similarity between query and document 12: 0.7100409879022886
Similarity between query and document 12: 0.7100409879022886
Similarity between query and document 13: 0.6894456528534281
Similarity between query and document 13: 0.6894456528534281
Similarity between query and document 13: 0.6894456528534281
Similarity between query and document 18: 0.7074180166182251
Similarity between query and document 18: 0.7074180166182251
Similarity between query and document 18: 0.7074180166182251
Similarity between query and document 19: 0.6937291276393807
Similarity between query and document 19: 0.6937291276393807
Similarity between query and document 19: 0.6937291276393807
Similarity between query and document 20: 0.7049862628673084
Similarity between query and document 20: 0.7049862628673084
Similarity between query and document 20: 0.7049862628673084
Similarity between query and document 27: 0.765845533393928
Similarity between query and document 27: 0.765845533393928
Similarity between query and document 27: 0.765845533393928
Similarity between query and document 29: 0.7154477209769697
Similarity between query and document 29: 0.7154477209769697
Similarity between query and document 29: 0.7154477209769697
Similarity between query and document 39: 0.696087913507082
Similarity between query and document 39: 0.696087913507082
Similarity between query and document 39: 0.696087913507082
Similarity between query and document 41: 0.6977910847681049
Similarity between query and document 41: 0.6977910847681049
Similarity between query and document 41: 0.6977910847681049
Similarity between query and document 8: 0.8077581039087642
Similarity between query and document 8: 0.8077581039087642
Similarity between query and document 8: 0.8077581039087642
Similarity between query and document 14: 0.6980929760836115
Similarity between query and document 14: 0.6980929760836115
Similarity between query and document 14: 0.6980929760836115
Similarity between query and document 15: 0.6659840043560903
Similarity between query and document 15: 0.6659840043560903
Similarity between query and document 15: 0.6659840043560903
Similarity between query and document 16: 0.6940954478702843
Similarity between query and document 16: 0.6940954478702843
Similarity between query and document 16: 0.6940954478702843
Similarity between query and document 17: 0.6947968686158548
Similarity between query and document 17: 0.6947968686158548
Similarity between query and document 17: 0.6947968686158548
Similarity between query and document 22: 0.6761567008964395
Similarity between query and document 22: 0.6761567008964395
Similarity between query and document 22: 0.6761567008964395
Similarity between query and document 23: 0.6853045449858939
Similarity between query and document 23: 0.6853045449858939
Similarity between query and document 23: 0.6853045449858939
Similarity between query and document 24: 0.6892485697976856
Similarity between query and document 24: 0.6892485697976856
Similarity between query and document 24: 0.6892485697976856
Similarity between query and document 34: 0.6725129935069931
Similarity between query and document 34: 0.6725129935069931
Similarity between query and document 34: 0.6725129935069931
Similarity between query and document 37: 0.6914194002040623
Similarity between query and document 37: 0.6914194002040623
Similarity between query and document 37: 0.6914194002040623
Similarity between query and document 38: 0.6743855494316493
Similarity between query and document 38: 0.6743855494316493
Similarity between query and document 38: 0.6743855494316493
Similarity between query and document 40: 0.7011187677089492
Similarity between query and document 40: 0.7011187677089492
Similarity between query and document 40: 0.7011187677089492
Similarity between query and document 36: 0.6767067254794891
Similarity between query and document 36: 0.6767067254794891
Similarity between query and document 36: 0.6767067254794891
Similarity between query and document 7: 0.766223311369925
Similarity between query and document 7: 0.766223311369925
Similarity between query and document 7: 0.766223311369925
Similarity between query and document 9: 0.738323994095123
Similarity between query and document 9: 0.738323994095123
Similarity between query and document 9: 0.738323994095123
Similarity between query and document 28: 0.7535872593732322
Similarity between query and document 28: 0.7535872593732322
Similarity between query and document 28: 0.7535872593732322
Similarity between query and document 25: 0.664709696433353
Similarity between query and document 25: 0.664709696433353
Similarity between query and document 25: 0.664709696433353
Similarity between query and document 26: 0.6594471713101954
Similarity between query and document 26: 0.6594471713101954
Similarity between query and document 26: 0.6594471713101954
Similarity between query and document 21: 0.7213011498198677
Similarity between query and document 21: 0.7213011498198677
Similarity between query and document 21: 0.7213011498198677
Similarity between query and document 35: 0.6720800783616144
Similarity between query and document 35: 0.6720800783616144
Similarity between query and document 35: 0.6720800783616144
Similarity between query and document 30: 0.682404088489988
Similarity between query and document 30: 0.682404088489988
Similarity between query and document 30: 0.682404088489988
Similarity between query and document 31: 0.7426141601959737
Similarity between query and document 31: 0.7426141601959737
Similarity between query and document 31: 0.7426141601959737
Similarity between query and document 33: 0.6709936450588483
Similarity between query and document 33: 0.6709936450588483
Similarity between query and document 33: 0.6709936450588483
Similarity between query and document 32: 0.7456254643390098
Similarity between query and document 32: 0.7456254643390098
Similarity between query and document 32: 0.7456254643390098
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7508650868972415
Similarity between query and document 0: 0.7508650868972415
Similarity between query and document 0: 0.7508650868972415
Similarity between query and document 1: 0.7468444153749878
Similarity between query and document 1: 0.7468444153749878
Similarity between query and document 1: 0.7468444153749878
Similarity between query and document 2: 0.7328411594192379
Similarity between query and document 2: 0.7328411594192379
Similarity between query and document 2: 0.7328411594192379
Similarity between query and document 3: 0.7992202289686003
Similarity between query and document 3: 0.7992202289686003
Similarity between query and document 3: 0.7992202289686003
Similarity between query and document 4: 0.708148091553021
Similarity between query and document 4: 0.708148091553021
Similarity between query and document 4: 0.708148091553021
Similarity between query and document 5: 0.7008865278503892
Similarity between query and document 5: 0.7008865278503892
Similarity between query and document 5: 0.7008865278503892
Similarity between query and document 6: 0.7046969470057726
Similarity between query and document 6: 0.7046969470057726
Similarity between query and document 6: 0.7046969470057726
Similarity between query and document 10: 0.6966151348261405
Similarity between query and document 10: 0.6966151348261405
Similarity between query and document 10: 0.6966151348261405
Similarity between query and document 11: 0.680983374928523
Similarity between query and document 11: 0.680983374928523
Similarity between query and document 11: 0.680983374928523
Similarity between query and document 12: 0.7095844221093405
Similarity between query and document 12: 0.7095844221093405
Similarity between query and document 12: 0.7095844221093405
Similarity between query and document 13: 0.6909425158516187
Similarity between query and document 13: 0.6909425158516187
Similarity between query and document 13: 0.6909425158516187
Similarity between query and document 18: 0.6982451823467347
Similarity between query and document 18: 0.6982451823467347
Similarity between query and document 18: 0.6982451823467347
Similarity between query and document 19: 0.6999992716687231
Similarity between query and document 19: 0.6999992716687231
Similarity between query and document 19: 0.6999992716687231
Similarity between query and document 20: 0.7063397482461725
Similarity between query and document 20: 0.7063397482461725
Similarity between query and document 20: 0.7063397482461725
Similarity between query and document 27: 0.7526304129972651
Similarity between query and document 27: 0.7526304129972651
Similarity between query and document 27: 0.7526304129972651
Similarity between query and document 29: 0.7144842510913088
Similarity between query and document 29: 0.7144842510913088
Similarity between query and document 29: 0.7144842510913088
Similarity between query and document 39: 0.6921033617015475
Similarity between query and document 39: 0.6921033617015475
Similarity between query and document 39: 0.6921033617015475
Similarity between query and document 41: 0.7029644640328377
Similarity between query and document 41: 0.7029644640328377
Similarity between query and document 41: 0.7029644640328377
Similarity between query and document 8: 0.7835927328052423
Similarity between query and document 8: 0.7835927328052423
Similarity between query and document 8: 0.7835927328052423
Similarity between query and document 14: 0.6916317801431013
Similarity between query and document 14: 0.6916317801431013
Similarity between query and document 14: 0.6916317801431013
Similarity between query and document 15: 0.6682992967466951
Similarity between query and document 15: 0.6682992967466951
Similarity between query and document 15: 0.6682992967466951
Similarity between query and document 16: 0.6903629153210235
Similarity between query and document 16: 0.6903629153210235
Similarity between query and document 16: 0.6903629153210235
Similarity between query and document 17: 0.6917879671044391
Similarity between query and document 17: 0.6917879671044391
Similarity between query and document 17: 0.6917879671044391
Similarity between query and document 22: 0.6686057739107966
Similarity between query and document 22: 0.6686057739107966
Similarity between query and document 22: 0.6686057739107966
Similarity between query and document 23: 0.6819695057817045
Similarity between query and document 23: 0.6819695057817045
Similarity between query and document 23: 0.6819695057817045
Similarity between query and document 24: 0.6854398207739454
Similarity between query and document 24: 0.6854398207739454
Similarity between query and document 24: 0.6854398207739454
Similarity between query and document 34: 0.6815126434173959
Similarity between query and document 34: 0.6815126434173959
Similarity between query and document 34: 0.6815126434173959
Similarity between query and document 37: 0.6896959746586209
Similarity between query and document 37: 0.6896959746586209
Similarity between query and document 37: 0.6896959746586209
Similarity between query and document 38: 0.6659648760812236
Similarity between query and document 38: 0.6659648760812236
Similarity between query and document 38: 0.6659648760812236
Similarity between query and document 40: 0.6994401116776354
Similarity between query and document 40: 0.6994401116776354
Similarity between query and document 40: 0.6994401116776354
Similarity between query and document 36: 0.674015692809921
Similarity between query and document 36: 0.674015692809921
Similarity between query and document 36: 0.674015692809921
Similarity between query and document 7: 0.7606089416645646
Similarity between query and document 7: 0.7606089416645646
Similarity between query and document 7: 0.7606089416645646
Similarity between query and document 9: 0.7367927898756234
Similarity between query and document 9: 0.7367927898756234
Similarity between query and document 9: 0.7367927898756234
Similarity between query and document 28: 0.727854883519909
Similarity between query and document 28: 0.727854883519909
Similarity between query and document 28: 0.727854883519909
Similarity between query and document 25: 0.6586277803353775
Similarity between query and document 25: 0.6586277803353775
Similarity between query and document 25: 0.6586277803353775
Similarity between query and document 26: 0.6505040847363615
Similarity between query and document 26: 0.6505040847363615
Similarity between query and document 26: 0.6505040847363615
Similarity between query and document 21: 0.7148859570347658
Similarity between query and document 21: 0.7148859570347658
Similarity between query and document 21: 0.7148859570347658
Similarity between query and document 35: 0.6805109485776966
Similarity between query and document 35: 0.6805109485776966
Similarity between query and document 35: 0.6805109485776966
Similarity between query and document 30: 0.6779467377552182
Similarity between query and document 30: 0.6779467377552182
Similarity between query and document 30: 0.6779467377552182
Similarity between query and document 31: 0.7432832451657039
Similarity between query and document 31: 0.7432832451657039
Similarity between query and document 31: 0.7432832451657039
Similarity between query and document 33: 0.6664175945044767
Similarity between query and document 33: 0.6664175945044767
Similarity between query and document 33: 0.6664175945044767
Similarity between query and document 32: 0.757689942717632
Similarity between query and document 32: 0.757689942717632
Similarity between query and document 32: 0.757689942717632
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.738794830914996
Similarity between query and document 0: 0.738794830914996
Similarity between query and document 0: 0.738794830914996
Similarity between query and document 1: 0.7283805641769692
Similarity between query and document 1: 0.7283805641769692
Similarity between query and document 1: 0.7283805641769692
Similarity between query and document 2: 0.7299076910258404
Similarity between query and document 2: 0.7299076910258404
Similarity between query and document 2: 0.7299076910258404
Similarity between query and document 3: 0.7970547841256435
Similarity between query and document 3: 0.7970547841256435
Similarity between query and document 3: 0.7970547841256435
Similarity between query and document 4: 0.7118431252280073
Similarity between query and document 4: 0.7118431252280073
Similarity between query and document 4: 0.7118431252280073
Similarity between query and document 5: 0.7015159172515872
Similarity between query and document 5: 0.7015159172515872
Similarity between query and document 5: 0.7015159172515872
Similarity between query and document 6: 0.704759064938254
Similarity between query and document 6: 0.704759064938254
Similarity between query and document 6: 0.704759064938254
Similarity between query and document 10: 0.7003578748322156
Similarity between query and document 10: 0.7003578748322156
Similarity between query and document 10: 0.7003578748322156
Similarity between query and document 11: 0.6878721900925792
Similarity between query and document 11: 0.6878721900925792
Similarity between query and document 11: 0.6878721900925792
Similarity between query and document 12: 0.705250511141571
Similarity between query and document 12: 0.705250511141571
Similarity between query and document 12: 0.705250511141571
Similarity between query and document 13: 0.6870953108171836
Similarity between query and document 13: 0.6870953108171836
Similarity between query and document 13: 0.6870953108171836
Similarity between query and document 18: 0.7093452126655966
Similarity between query and document 18: 0.7093452126655966
Similarity between query and document 18: 0.7093452126655966
Similarity between query and document 19: 0.6879912361793814
Similarity between query and document 19: 0.6879912361793814
Similarity between query and document 19: 0.6879912361793814
Similarity between query and document 20: 0.7043893775548762
Similarity between query and document 20: 0.7043893775548762
Similarity between query and document 20: 0.7043893775548762
Similarity between query and document 27: 0.7672591836206646
Similarity between query and document 27: 0.7672591836206646
Similarity between query and document 27: 0.7672591836206646
Similarity between query and document 29: 0.7184451674189832
Similarity between query and document 29: 0.7184451674189832
Similarity between query and document 29: 0.7184451674189832
Similarity between query and document 39: 0.6997143192577967
Similarity between query and document 39: 0.6997143192577967
Similarity between query and document 39: 0.6997143192577967
Similarity between query and document 41: 0.6923482908861842
Similarity between query and document 41: 0.6923482908861842
Similarity between query and document 41: 0.6923482908861842
Similarity between query and document 8: 0.8145065468766138
Similarity between query and document 8: 0.8145065468766138
Similarity between query and document 8: 0.8145065468766138
Similarity between query and document 14: 0.699507517575833
Similarity between query and document 14: 0.699507517575833
Similarity between query and document 14: 0.699507517575833
Similarity between query and document 15: 0.6651304372619934
Similarity between query and document 15: 0.6651304372619934
Similarity between query and document 15: 0.6651304372619934
Similarity between query and document 16: 0.6930330717842998
Similarity between query and document 16: 0.6930330717842998
Similarity between query and document 16: 0.6930330717842998
Similarity between query and document 17: 0.6930386865704673
Similarity between query and document 17: 0.6930386865704673
Similarity between query and document 17: 0.6930386865704673
Similarity between query and document 22: 0.6825550952647861
Similarity between query and document 22: 0.6825550952647861
Similarity between query and document 22: 0.6825550952647861
Similarity between query and document 23: 0.6969013794600043
Similarity between query and document 23: 0.6969013794600043
Similarity between query and document 23: 0.6969013794600043
Similarity between query and document 24: 0.6910516249816243
Similarity between query and document 24: 0.6910516249816243
Similarity between query and document 24: 0.6910516249816243
Similarity between query and document 34: 0.6733457180819568
Similarity between query and document 34: 0.6733457180819568
Similarity between query and document 34: 0.6733457180819568
Similarity between query and document 37: 0.6984299003936549
Similarity between query and document 37: 0.6984299003936549
Similarity between query and document 37: 0.6984299003936549
Similarity between query and document 38: 0.6802820634197568
Similarity between query and document 38: 0.6802820634197568
Similarity between query and document 38: 0.6802820634197568
Similarity between query and document 40: 0.7019155297484577
Similarity between query and document 40: 0.7019155297484577
Similarity between query and document 40: 0.7019155297484577
Similarity between query and document 36: 0.6839805374087112
Similarity between query and document 36: 0.6839805374087112
Similarity between query and document 36: 0.6839805374087112
Similarity between query and document 7: 0.7711637474076771
Similarity between query and document 7: 0.7711637474076771
Similarity between query and document 7: 0.7711637474076771
Similarity between query and document 9: 0.7398870889708926
Similarity between query and document 9: 0.7398870889708926
Similarity between query and document 9: 0.7398870889708926
Similarity between query and document 28: 0.7707492407874111
Similarity between query and document 28: 0.7707492407874111
Similarity between query and document 28: 0.7707492407874111
Similarity between query and document 25: 0.6751583371718848
Similarity between query and document 25: 0.6751583371718848
Similarity between query and document 25: 0.6751583371718848
Similarity between query and document 26: 0.6678119086678739
Similarity between query and document 26: 0.6678119086678739
Similarity between query and document 26: 0.6678119086678739
Similarity between query and document 21: 0.7253859321357389
Similarity between query and document 21: 0.7253859321357389
Similarity between query and document 21: 0.7253859321357389
Similarity between query and document 35: 0.6763151617083303
Similarity between query and document 35: 0.6763151617083303
Similarity between query and document 35: 0.6763151617083303
Similarity between query and document 30: 0.686806500764452
Similarity between query and document 30: 0.686806500764452
Similarity between query and document 30: 0.686806500764452
Similarity between query and document 31: 0.7392773247708659
Similarity between query and document 31: 0.7392773247708659
Similarity between query and document 31: 0.7392773247708659
Similarity between query and document 33: 0.6743266296665984
Similarity between query and document 33: 0.6743266296665984
Similarity between query and document 33: 0.6743266296665984
Similarity between query and document 32: 0.7504503971609473
Similarity between query and document 32: 0.7504503971609473
Similarity between query and document 32: 0.7504503971609473
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Similarity between query and document 0: 0.7414389291663663
Similarity between query and document 0: 0.7414389291663663
Similarity between query and document 0: 0.7414389291663663
Similarity between query and document 0: 0.7414389291663663
Similarity between query and document 1: 0.7343254056492652
Similarity between query and document 1: 0.7343254056492652
Similarity between query and document 1: 0.7343254056492652
Similarity between query and document 1: 0.7343254056492652
Similarity between query and document 2: 0.7273533634423212
Similarity between query and document 2: 0.7273533634423212
Similarity between query and document 2: 0.7273533634423212
Similarity between query and document 2: 0.7273533634423212
Similarity between query and document 3: 0.8040877518887549
Similarity between query and document 3: 0.8040877518887549
Similarity between query and document 3: 0.8040877518887549
Similarity between query and document 3: 0.8040877518887549
Similarity between query and document 4: 0.7160654249915577
Similarity between query and document 4: 0.7160654249915577
Similarity between query and document 4: 0.7160654249915577
Similarity between query and document 4: 0.7160654249915577
Similarity between query and document 5: 0.7088639125212659
Similarity between query and document 5: 0.7088639125212659
Similarity between query and document 5: 0.7088639125212659
Similarity between query and document 5: 0.7088639125212659
Similarity between query and document 6: 0.7135072268549127
Similarity between query and document 6: 0.7135072268549127
Similarity between query and document 6: 0.7135072268549127
Similarity between query and document 6: 0.7135072268549127
Similarity between query and document 10: 0.7065027186698403
Similarity between query and document 10: 0.7065027186698403
Similarity between query and document 10: 0.7065027186698403
Similarity between query and document 10: 0.7065027186698403
Similarity between query and document 11: 0.6980406438332847
Similarity between query and document 11: 0.6980406438332847
Similarity between query and document 11: 0.6980406438332847
Similarity between query and document 11: 0.6980406438332847
Similarity between query and document 12: 0.7053067867301341
Similarity between query and document 12: 0.7053067867301341
Similarity between query and document 12: 0.7053067867301341
Similarity between query and document 12: 0.7053067867301341
Similarity between query and document 13: 0.6999335310974926
Similarity between query and document 13: 0.6999335310974926
Similarity between query and document 13: 0.6999335310974926
Similarity between query and document 13: 0.6999335310974926
Similarity between query and document 18: 0.7062496449033052
Similarity between query and document 18: 0.7062496449033052
Similarity between query and document 18: 0.7062496449033052
Similarity between query and document 18: 0.7062496449033052
Similarity between query and document 19: 0.6941963489505044
Similarity between query and document 19: 0.6941963489505044
Similarity between query and document 19: 0.6941963489505044
Similarity between query and document 19: 0.6941963489505044
Similarity between query and document 20: 0.7152793647316348
Similarity between query and document 20: 0.7152793647316348
Similarity between query and document 20: 0.7152793647316348
Similarity between query and document 20: 0.7152793647316348
Similarity between query and document 27: 0.77171000209844
Similarity between query and document 27: 0.77171000209844
Similarity between query and document 27: 0.77171000209844
Similarity between query and document 27: 0.77171000209844
Similarity between query and document 29: 0.7275104847015552
Similarity between query and document 29: 0.7275104847015552
Similarity between query and document 29: 0.7275104847015552
Similarity between query and document 29: 0.7275104847015552
Similarity between query and document 39: 0.714573697472876
Similarity between query and document 39: 0.714573697472876
Similarity between query and document 39: 0.714573697472876
Similarity between query and document 39: 0.714573697472876
Similarity between query and document 41: 0.7027393638960043
Similarity between query and document 41: 0.7027393638960043
Similarity between query and document 41: 0.7027393638960043
Similarity between query and document 41: 0.7027393638960043
Similarity between query and document 8: 0.8267317589819251
Similarity between query and document 8: 0.8267317589819251
Similarity between query and document 8: 0.8267317589819251
Similarity between query and document 8: 0.8267317589819251
Similarity between query and document 14: 0.7060076485179293
Similarity between query and document 14: 0.7060076485179293
Similarity between query and document 14: 0.7060076485179293
Similarity between query and document 14: 0.7060076485179293
Similarity between query and document 15: 0.6802073303938283
Similarity between query and document 15: 0.6802073303938283
Similarity between query and document 15: 0.6802073303938283
Similarity between query and document 15: 0.6802073303938283
Similarity between query and document 16: 0.7002080264957098
Similarity between query and document 16: 0.7002080264957098
Similarity between query and document 16: 0.7002080264957098
Similarity between query and document 16: 0.7002080264957098
Similarity between query and document 17: 0.7079933197846948
Similarity between query and document 17: 0.7079933197846948
Similarity between query and document 17: 0.7079933197846948
Similarity between query and document 17: 0.7079933197846948
Similarity between query and document 22: 0.6989891626328539
Similarity between query and document 22: 0.6989891626328539
Similarity between query and document 22: 0.6989891626328539
Similarity between query and document 22: 0.6989891626328539
Similarity between query and document 23: 0.7112437726880984
Similarity between query and document 23: 0.7112437726880984
Similarity between query and document 23: 0.7112437726880984
Similarity between query and document 23: 0.7112437726880984
Similarity between query and document 24: 0.7043663956490136
Similarity between query and document 24: 0.7043663956490136
Similarity between query and document 24: 0.7043663956490136
Similarity between query and document 24: 0.7043663956490136
Similarity between query and document 34: 0.6752447905925607
Similarity between query and document 34: 0.6752447905925607
Similarity between query and document 34: 0.6752447905925607
Similarity between query and document 34: 0.6752447905925607
Similarity between query and document 37: 0.7017798502959522
Similarity between query and document 37: 0.7017798502959522
Similarity between query and document 37: 0.7017798502959522
Similarity between query and document 37: 0.7017798502959522
Similarity between query and document 38: 0.6886291180561472
Similarity between query and document 38: 0.6886291180561472
Similarity between query and document 38: 0.6886291180561472
Similarity between query and document 38: 0.6886291180561472
Similarity between query and document 40: 0.7042666013962384
Similarity between query and document 40: 0.7042666013962384
Similarity between query and document 40: 0.7042666013962384
Similarity between query and document 40: 0.7042666013962384
Similarity between query and document 36: 0.7016620746764255
Similarity between query and document 36: 0.7016620746764255
Similarity between query and document 36: 0.7016620746764255
Similarity between query and document 36: 0.7016620746764255
Similarity between query and document 7: 0.7749230396508466
Similarity between query and document 7: 0.7749230396508466
Similarity between query and document 7: 0.7749230396508466
Similarity between query and document 7: 0.7749230396508466
Similarity between query and document 9: 0.7463811267344076
Similarity between query and document 9: 0.7463811267344076
Similarity between query and document 9: 0.7463811267344076
Similarity between query and document 9: 0.7463811267344076
Similarity between query and document 28: 0.7782352458189601
Similarity between query and document 28: 0.7782352458189601
Similarity between query and document 28: 0.7782352458189601
Similarity between query and document 28: 0.7782352458189601
Similarity between query and document 25: 0.6826297013495308
Similarity between query and document 25: 0.6826297013495308
Similarity between query and document 25: 0.6826297013495308
Similarity between query and document 25: 0.6826297013495308
Similarity between query and document 26: 0.6808966548983042
Similarity between query and document 26: 0.6808966548983042
Similarity between query and document 26: 0.6808966548983042
Similarity between query and document 26: 0.6808966548983042
Similarity between query and document 21: 0.7351801928300795
Similarity between query and document 21: 0.7351801928300795
Similarity between query and document 21: 0.7351801928300795
Similarity between query and document 21: 0.7351801928300795
Similarity between query and document 35: 0.6888554977191607
Similarity between query and document 35: 0.6888554977191607
Similarity between query and document 35: 0.6888554977191607
Similarity between query and document 35: 0.6888554977191607
Similarity between query and document 30: 0.6881324943852023
Similarity between query and document 30: 0.6881324943852023
Similarity between query and document 30: 0.6881324943852023
Similarity between query and document 30: 0.6881324943852023
Similarity between query and document 31: 0.7329666455394842
Similarity between query and document 31: 0.7329666455394842
Similarity between query and document 31: 0.7329666455394842
Similarity between query and document 31: 0.7329666455394842
Similarity between query and document 33: 0.6809819785499938
Similarity between query and document 33: 0.6809819785499938
Similarity between query and document 33: 0.6809819785499938
Similarity between query and document 33: 0.6809819785499938
Similarity between query and document 32: 0.7537056715433319
Similarity between query and document 32: 0.7537056715433319
Similarity between query and document 32: 0.7537056715433319
Similarity between query and document 32: 0.7537056715433319
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Similarity between query and document 0: 0.7595701653686106
Similarity between query and document 0: 0.7595701653686106
Similarity between query and document 0: 0.7595701653686106
Similarity between query and document 0: 0.7595701653686106
Similarity between query and document 0: 0.7595701653686106
Similarity between query and document 1: 0.7589250023075543
Similarity between query and document 1: 0.7589250023075543
Similarity between query and document 1: 0.7589250023075543
Similarity between query and document 1: 0.7589250023075543
Similarity between query and document 1: 0.7589250023075543
Similarity between query and document 2: 0.7423473930847293
Similarity between query and document 2: 0.7423473930847293
Similarity between query and document 2: 0.7423473930847293
Similarity between query and document 2: 0.7423473930847293
Similarity between query and document 2: 0.7423473930847293
Similarity between query and document 3: 0.7956344171648867
Similarity between query and document 3: 0.7956344171648867
Similarity between query and document 3: 0.7956344171648867
Similarity between query and document 3: 0.7956344171648867
Similarity between query and document 3: 0.7956344171648867
Similarity between query and document 4: 0.7097441826729484
Similarity between query and document 4: 0.7097441826729484
Similarity between query and document 4: 0.7097441826729484
Similarity between query and document 4: 0.7097441826729484
Similarity between query and document 4: 0.7097441826729484
Similarity between query and document 5: 0.7044282184353453
Similarity between query and document 5: 0.7044282184353453
Similarity between query and document 5: 0.7044282184353453
Similarity between query and document 5: 0.7044282184353453
Similarity between query and document 5: 0.7044282184353453
Similarity between query and document 6: 0.705283743138688
Similarity between query and document 6: 0.705283743138688
Similarity between query and document 6: 0.705283743138688
Similarity between query and document 6: 0.705283743138688
Similarity between query and document 6: 0.705283743138688
Similarity between query and document 10: 0.69387012268009
Similarity between query and document 10: 0.69387012268009
Similarity between query and document 10: 0.69387012268009
Similarity between query and document 10: 0.69387012268009
Similarity between query and document 10: 0.69387012268009
Similarity between query and document 11: 0.692621635792856
Similarity between query and document 11: 0.692621635792856
Similarity between query and document 11: 0.692621635792856
Similarity between query and document 11: 0.692621635792856
Similarity between query and document 11: 0.692621635792856
Similarity between query and document 12: 0.6973410427468266
Similarity between query and document 12: 0.6973410427468266
Similarity between query and document 12: 0.6973410427468266
Similarity between query and document 12: 0.6973410427468266
Similarity between query and document 12: 0.6973410427468266
Similarity between query and document 13: 0.6934035590074501
Similarity between query and document 13: 0.6934035590074501
Similarity between query and document 13: 0.6934035590074501
Similarity between query and document 13: 0.6934035590074501
Similarity between query and document 13: 0.6934035590074501
Similarity between query and document 18: 0.7248134596493789
Similarity between query and document 18: 0.7248134596493789
Similarity between query and document 18: 0.7248134596493789
Similarity between query and document 18: 0.7248134596493789
Similarity between query and document 18: 0.7248134596493789
Similarity between query and document 19: 0.7031574540408891
Similarity between query and document 19: 0.7031574540408891
Similarity between query and document 19: 0.7031574540408891
Similarity between query and document 19: 0.7031574540408891
Similarity between query and document 19: 0.7031574540408891
Similarity between query and document 20: 0.7141817303545444
Similarity between query and document 20: 0.7141817303545444
Similarity between query and document 20: 0.7141817303545444
Similarity between query and document 20: 0.7141817303545444
Similarity between query and document 20: 0.7141817303545444
Similarity between query and document 27: 0.7223386579116226
Similarity between query and document 27: 0.7223386579116226
Similarity between query and document 27: 0.7223386579116226
Similarity between query and document 27: 0.7223386579116226
Similarity between query and document 27: 0.7223386579116226
Similarity between query and document 29: 0.6950770483040241
Similarity between query and document 29: 0.6950770483040241
Similarity between query and document 29: 0.6950770483040241
Similarity between query and document 29: 0.6950770483040241
Similarity between query and document 29: 0.6950770483040241
Similarity between query and document 39: 0.6832984031282001
Similarity between query and document 39: 0.6832984031282001
Similarity between query and document 39: 0.6832984031282001
Similarity between query and document 39: 0.6832984031282001
Similarity between query and document 39: 0.6832984031282001
Similarity between query and document 41: 0.7196965039018125
Similarity between query and document 41: 0.7196965039018125
Similarity between query and document 41: 0.7196965039018125
Similarity between query and document 41: 0.7196965039018125
Similarity between query and document 41: 0.7196965039018125
Similarity between query and document 8: 0.7617459279591693
Similarity between query and document 8: 0.7617459279591693
Similarity between query and document 8: 0.7617459279591693
Similarity between query and document 8: 0.7617459279591693
Similarity between query and document 8: 0.7617459279591693
Similarity between query and document 14: 0.6958226475069016
Similarity between query and document 14: 0.6958226475069016
Similarity between query and document 14: 0.6958226475069016
Similarity between query and document 14: 0.6958226475069016
Similarity between query and document 14: 0.6958226475069016
Similarity between query and document 15: 0.6806420709012786
Similarity between query and document 15: 0.6806420709012786
Similarity between query and document 15: 0.6806420709012786
Similarity between query and document 15: 0.6806420709012786
Similarity between query and document 15: 0.6806420709012786
Similarity between query and document 16: 0.7032133936345861
Similarity between query and document 16: 0.7032133936345861
Similarity between query and document 16: 0.7032133936345861
Similarity between query and document 16: 0.7032133936345861
Similarity between query and document 16: 0.7032133936345861
Similarity between query and document 17: 0.7084857573719587
Similarity between query and document 17: 0.7084857573719587
Similarity between query and document 17: 0.7084857573719587
Similarity between query and document 17: 0.7084857573719587
Similarity between query and document 17: 0.7084857573719587
Similarity between query and document 22: 0.6827189141630747
Similarity between query and document 22: 0.6827189141630747
Similarity between query and document 22: 0.6827189141630747
Similarity between query and document 22: 0.6827189141630747
Similarity between query and document 22: 0.6827189141630747
Similarity between query and document 23: 0.6832903375861509
Similarity between query and document 23: 0.6832903375861509
Similarity between query and document 23: 0.6832903375861509
Similarity between query and document 23: 0.6832903375861509
Similarity between query and document 23: 0.6832903375861509
Similarity between query and document 24: 0.6928611659026329
Similarity between query and document 24: 0.6928611659026329
Similarity between query and document 24: 0.6928611659026329
Similarity between query and document 24: 0.6928611659026329
Similarity between query and document 24: 0.6928611659026329
Similarity between query and document 34: 0.6924348498066608
Similarity between query and document 34: 0.6924348498066608
Similarity between query and document 34: 0.6924348498066608
Similarity between query and document 34: 0.6924348498066608
Similarity between query and document 34: 0.6924348498066608
Similarity between query and document 37: 0.6801086257924296
Similarity between query and document 37: 0.6801086257924296
Similarity between query and document 37: 0.6801086257924296
Similarity between query and document 37: 0.6801086257924296
Similarity between query and document 37: 0.6801086257924296
Similarity between query and document 38: 0.6767761116128548
Similarity between query and document 38: 0.6767761116128548
Similarity between query and document 38: 0.6767761116128548
Similarity between query and document 38: 0.6767761116128548
Similarity between query and document 38: 0.6767761116128548
Similarity between query and document 40: 0.6936580274358233
Similarity between query and document 40: 0.6936580274358233
Similarity between query and document 40: 0.6936580274358233
Similarity between query and document 40: 0.6936580274358233
Similarity between query and document 40: 0.6936580274358233
Similarity between query and document 36: 0.6802757868889303
Similarity between query and document 36: 0.6802757868889303
Similarity between query and document 36: 0.6802757868889303
Similarity between query and document 36: 0.6802757868889303
Similarity between query and document 36: 0.6802757868889303
Similarity between query and document 7: 0.7441025864257134
Similarity between query and document 7: 0.7441025864257134
Similarity between query and document 7: 0.7441025864257134
Similarity between query and document 7: 0.7441025864257134
Similarity between query and document 7: 0.7441025864257134
Similarity between query and document 9: 0.7572985124304226
Similarity between query and document 9: 0.7572985124304226
Similarity between query and document 9: 0.7572985124304226
Similarity between query and document 9: 0.7572985124304226
Similarity between query and document 9: 0.7572985124304226
Similarity between query and document 28: 0.7119283510160543
Similarity between query and document 28: 0.7119283510160543
Similarity between query and document 28: 0.7119283510160543
Similarity between query and document 28: 0.7119283510160543
Similarity between query and document 28: 0.7119283510160543
Similarity between query and document 25: 0.658540709955467
Similarity between query and document 25: 0.658540709955467
Similarity between query and document 25: 0.658540709955467
Similarity between query and document 25: 0.658540709955467
Similarity between query and document 25: 0.658540709955467
Similarity between query and document 26: 0.6596775630755276
Similarity between query and document 26: 0.6596775630755276
Similarity between query and document 26: 0.6596775630755276
Similarity between query and document 26: 0.6596775630755276
Similarity between query and document 26: 0.6596775630755276
Similarity between query and document 21: 0.7180026815613558
Similarity between query and document 21: 0.7180026815613558
Similarity between query and document 21: 0.7180026815613558
Similarity between query and document 21: 0.7180026815613558
Similarity between query and document 21: 0.7180026815613558
Similarity between query and document 35: 0.6857553542805048
Similarity between query and document 35: 0.6857553542805048
Similarity between query and document 35: 0.6857553542805048
Similarity between query and document 35: 0.6857553542805048
Similarity between query and document 35: 0.6857553542805048
Similarity between query and document 30: 0.6848443581547141
Similarity between query and document 30: 0.6848443581547141
Similarity between query and document 30: 0.6848443581547141
Similarity between query and document 30: 0.6848443581547141
Similarity between query and document 30: 0.6848443581547141
Similarity between query and document 31: 0.7072174511609208
Similarity between query and document 31: 0.7072174511609208
Similarity between query and document 31: 0.7072174511609208
Similarity between query and document 31: 0.7072174511609208
Similarity between query and document 31: 0.7072174511609208
Similarity between query and document 33: 0.6820401706903805
Similarity between query and document 33: 0.6820401706903805
Similarity between query and document 33: 0.6820401706903805
Similarity between query and document 33: 0.6820401706903805
Similarity between query and document 33: 0.6820401706903805
Similarity between query and document 32: 0.7056086909354164
Similarity between query and document 32: 0.7056086909354164
Similarity between query and document 32: 0.7056086909354164
Similarity between query and document 32: 0.7056086909354164
Similarity between query and document 32: 0.7056086909354164
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.7721087786698699
Similarity between query and document 0: 0.7721087786698699
Similarity between query and document 0: 0.7721087786698699
Similarity between query and document 1: 0.772595848962941
Similarity between query and document 1: 0.772595848962941
Similarity between query and document 1: 0.772595848962941
Similarity between query and document 2: 0.7562174098226594
Similarity between query and document 2: 0.7562174098226594
Similarity between query and document 2: 0.7562174098226594
Similarity between query and document 3: 0.817280957148152
Similarity between query and document 3: 0.817280957148152
Similarity between query and document 3: 0.817280957148152
Similarity between query and document 4: 0.7075764206912811
Similarity between query and document 4: 0.7075764206912811
Similarity between query and document 4: 0.7075764206912811
Similarity between query and document 5: 0.7122823855561489
Similarity between query and document 5: 0.7122823855561489
Similarity between query and document 5: 0.7122823855561489
Similarity between query and document 6: 0.7041684176062613
Similarity between query and document 6: 0.7041684176062613
Similarity between query and document 6: 0.7041684176062613
Similarity between query and document 10: 0.7012109177637182
Similarity between query and document 10: 0.7012109177637182
Similarity between query and document 10: 0.7012109177637182
Similarity between query and document 11: 0.6870639753746302
Similarity between query and document 11: 0.6870639753746302
Similarity between query and document 11: 0.6870639753746302
Similarity between query and document 12: 0.6959304044514961
Similarity between query and document 12: 0.6959304044514961
Similarity between query and document 12: 0.6959304044514961
Similarity between query and document 13: 0.7020047106658514
Similarity between query and document 13: 0.7020047106658514
Similarity between query and document 13: 0.7020047106658514
Similarity between query and document 18: 0.71061553656399
Similarity between query and document 18: 0.71061553656399
Similarity between query and document 18: 0.71061553656399
Similarity between query and document 19: 0.7000427087784664
Similarity between query and document 19: 0.7000427087784664
Similarity between query and document 19: 0.7000427087784664
Similarity between query and document 20: 0.7055657779262575
Similarity between query and document 20: 0.7055657779262575
Similarity between query and document 20: 0.7055657779262575
Similarity between query and document 27: 0.7173204466748994
Similarity between query and document 27: 0.7173204466748994
Similarity between query and document 27: 0.7173204466748994
Similarity between query and document 29: 0.6986934847880839
Similarity between query and document 29: 0.6986934847880839
Similarity between query and document 29: 0.6986934847880839
Similarity between query and document 39: 0.6788580525350313
Similarity between query and document 39: 0.6788580525350313
Similarity between query and document 39: 0.6788580525350313
Similarity between query and document 41: 0.725052563124355
Similarity between query and document 41: 0.725052563124355
Similarity between query and document 41: 0.725052563124355
Similarity between query and document 8: 0.7623541099034448
Similarity between query and document 8: 0.7623541099034448
Similarity between query and document 8: 0.7623541099034448
Similarity between query and document 14: 0.6973766475639483
Similarity between query and document 14: 0.6973766475639483
Similarity between query and document 14: 0.6973766475639483
Similarity between query and document 15: 0.6811475281967835
Similarity between query and document 15: 0.6811475281967835
Similarity between query and document 15: 0.6811475281967835
Similarity between query and document 16: 0.7123299502410272
Similarity between query and document 16: 0.7123299502410272
Similarity between query and document 16: 0.7123299502410272
Similarity between query and document 17: 0.7185367688823254
Similarity between query and document 17: 0.7185367688823254
Similarity between query and document 17: 0.7185367688823254
Similarity between query and document 22: 0.6770562446331103
Similarity between query and document 22: 0.6770562446331103
Similarity between query and document 22: 0.6770562446331103
Similarity between query and document 23: 0.6809284521905168
Similarity between query and document 23: 0.6809284521905168
Similarity between query and document 23: 0.6809284521905168
Similarity between query and document 24: 0.6914138804585607
Similarity between query and document 24: 0.6914138804585607
Similarity between query and document 24: 0.6914138804585607
Similarity between query and document 34: 0.6831154807694955
Similarity between query and document 34: 0.6831154807694955
Similarity between query and document 34: 0.6831154807694955
Similarity between query and document 37: 0.6847682315168842
Similarity between query and document 37: 0.6847682315168842
Similarity between query and document 37: 0.6847682315168842
Similarity between query and document 38: 0.6769308353508748
Similarity between query and document 38: 0.6769308353508748
Similarity between query and document 38: 0.6769308353508748
Similarity between query and document 40: 0.6820057135622138
Similarity between query and document 40: 0.6820057135622138
Similarity between query and document 40: 0.6820057135622138
Similarity between query and document 36: 0.6832037470781708
Similarity between query and document 36: 0.6832037470781708
Similarity between query and document 36: 0.6832037470781708
Similarity between query and document 7: 0.7422940108690865
Similarity between query and document 7: 0.7422940108690865
Similarity between query and document 7: 0.7422940108690865
Similarity between query and document 9: 0.7407343992584043
Similarity between query and document 9: 0.7407343992584043
Similarity between query and document 9: 0.7407343992584043
Similarity between query and document 28: 0.7125192458244161
Similarity between query and document 28: 0.7125192458244161
Similarity between query and document 28: 0.7125192458244161
Similarity between query and document 25: 0.6708019806046116
Similarity between query and document 25: 0.6708019806046116
Similarity between query and document 25: 0.6708019806046116
Similarity between query and document 26: 0.6643530870225028
Similarity between query and document 26: 0.6643530870225028
Similarity between query and document 26: 0.6643530870225028
Similarity between query and document 21: 0.714149542985038
Similarity between query and document 21: 0.714149542985038
Similarity between query and document 21: 0.714149542985038
Similarity between query and document 35: 0.674615620016308
Similarity between query and document 35: 0.674615620016308
Similarity between query and document 35: 0.674615620016308
Similarity between query and document 30: 0.6820470789148141
Similarity between query and document 30: 0.6820470789148141
Similarity between query and document 30: 0.6820470789148141
Similarity between query and document 31: 0.6923555413045073
Similarity between query and document 31: 0.6923555413045073
Similarity between query and document 31: 0.6923555413045073
Similarity between query and document 33: 0.6783854528238126
Similarity between query and document 33: 0.6783854528238126
Similarity between query and document 33: 0.6783854528238126
Similarity between query and document 32: 0.692190524296076
Similarity between query and document 32: 0.692190524296076
Similarity between query and document 32: 0.692190524296076
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Data loaded: [Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 0}, page_content=' \n \n VISVESVARAYA TECHNOLOGICAL UNIVERSITY, \nBELGAUM, KARNATAKA \n \n PROJECT REPORT  \n \nON \n \n“PLANT LEAF DISEASE DETECTION” \n \nSubmitted in partial fulfillment of the requirement for the award of the degree of \n \nBACHELOR OF ENGINEERING \nIN \nCOMPUTER SCIENCE AND ENGINEERING \n \nSubmitted by \n \nUSN NAME \n \n         2SD17CS108                TEJAS M P \n                                                                      2SD17CS044                MANOJ C NAIK \n                  2SD17CS066                PRASHANT KALLI \n 2SD17CS072                RAHUL A \n            \nUnder the Guidance of \nDr. U P Kulkarni.  \nDept. of CSE, SDMCET, Dharwad \n \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \nS.D.M. COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD-580002 \n2020-2021\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 1}, page_content=' \n \n \nS.D.M COLLEGE OF ENGINEERING & TECHNOLOGY, \nDHARWAD –580002 \n \n \nDEPARTMENT OF COMPUTER SCIENCE AND ENGINEERING \n \nCERTIFICATE  \n \nCertified that the project work and presentation entitled  “PLANT LEAF \nDISEASE DETECTION ” is a bonafide work carried out by  TEJAS M P \n(2SD17CS108) PRASHANT KALLI (2SD17CS066), RAHUL A (2SD17CS072), \nand MANOJ C NAIK (2SD17CS044) , students of S. D. M. College of Engineering \n& Technology, Dharwad, in partial fulfil lment for the award of  Bachelor of \nEngineering in Computer Science and Engineering  of Visvesvaraya \nTechnological University , Belgaum, during the year 2020 -2021. It is certified that \nall corrections/suggestions indicated for internal a ssessment have been \nincorporated in the report deposited in the department library. The Project has been \napproved, as it satisfies the academic r equirements in respect of project report  \nprescribed for the said degree. \n \n \n \nDr. U P Kulkarni                 \nProject Guide and HoD-CSE                  \nExternal Viva \nName of Examiners      Signature with date \n1. _____________________ \n2. ___________________\n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 2}, page_content=' \nPage 1 of 19 \n \n \nABSTRACT \n \nCrop disease is a serious concern for safety of food, but its fast detection still remains \ndifficult in different parts of the lack of proper infrastructure Automatic identification of \nplant disease is necessary for food security, yield loss esti mation and management of \ndisease. With the worldwide increase in digital cameras and continuous improvements in \ncomputer vision domain, the automated techniques for detection of disease are highly in \ndemands in precision agriculture. Working on a dataset w hich includes images of crop \nleaves, a Residual Network was trained to perform this task of classification, The proposed \nResNet model accomplished a 99.40% accuracy on a test set, illustrating the viability of the \nproposed model. Overall the process of tra ining ResNet models on an open image dataset \nprovides a sound way towards crop disease detection using automated networks on an \nenormous global scale. Providing the user -friendly website for leaf disease detection to \nfarmers \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 3}, page_content='PLANT LEAF DISEASE DETECTION \nPage 2 of 17 \n \n \nTable of Contents \n \nPROBLEM STATEMENT ................................ ................................ ................................ ................................ ......... 3 \nCHAPTER 1: INTRODUCTION ................................ ................................ ................................ ................................  4 \nCHAPTER 2: LITERATURE SURVEY ................................ ................................ ................................ .....................  5 \nCHAPTER 3: DETAILED DESIGN ................................ ................................ ................................ ...........................  6 \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS ................................ ................................ .............................  9 \nCHAPTER 5: IMPLEMENTATION ................................ ................................ ................................ ........................  10 \nCHAPTER 6: RESULTS ................................ ................................ ................................ ................................ .......... 14 \nREFERENCES ................................ ................................ ................................ ................................ .........................  17 \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 4}, page_content='PLANT LEAF DISEASE DETECTION \nPage 3 of 17 \n \n \n \nPROBLEM STATEMENT \n \nPlant Leaf Disease Detection using PyTorch and Deep Learning \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 5}, page_content='PLANT LEAF DISEASE DETECTION \nPage 4 of 17 \n \n \nCHAPTER 1: INTRODUCTION \n \n In agricultural crops, leaves play a vital role to provide information about the amount and nature of \nhorticultural yield. Several factors affect food production such as climate change, presence of weed, and \nsoil infertility. Apart from that, plant or leaf disease is a global threat to the growth of several \nagricultural products and a source of economic losses. The failure to diagnose infections/bacteria/virus \nin plants leads subsequently to insufficient pesticide/fungicide use . Therefore, plant diseases have been \nlargely considered in the scientific community, with a focus on the biological features of diseases. \nPrecision farming uses the most advanced technology for the optimization of decision -making. The \nvisual inspections by experts and biological review are usually carried out through plant diagnosis when \nrequired. This method, however, is typically time -consuming and cost ineffective. To address these \nissues, it is necessary to detect plant diseases by advanced and intelligent techniques \n \nAs a solution to  this  problem,  we  have  devised  a  system  that  uses  deep  learning  to  analyze, \ndetect  and classify  any disease  that might have  affected  a plant by  taking  an image of  the leaf.  The \nprocessing pipeline goes as follows:  \n1. The leaf is detected in the given image and cropped out \n2. The extracted leaf is then run through a classifier to identify which plant the leaf belongs to  \n3. The leaf is then checked for the disease class, if any, based on the result it displays \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 6}, page_content='PLANT LEAF DISEASE DETECTION \nPage 5 of 17 \n \n \nCHAPTER 2: LITERATURE SURVEY \n \n Kaiming He et al.,  (2015) Proposed on " Deep Residual Learning for Image Recognition  " Deeper \nneural networks are more difficult to train. We present a residual learning framework to ease the training of \nnetworks that are substantially deeper than those used previously. We explicitly reformulate the layers as \nlearning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We \nprovide comprehensive empirical evidence showing that these residual networks are easier to optimize, and \ncan gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets \nwith a depth of up to 152 layers —8x deeper than VGG nets but still having lower complexity. An ensemble \nof these residual nets achieves 3.57% error on the ImageNet test set.  \n \nBAOQI LI et al.,( 2018), proposed work on  "An Improved ResNet Based on the Adjustable Shortcut \nConnections" In this paper, ResNet can achieve deeper network and higher performance, but there is no \ngood explanation for how identity short cut connections solve the gradient fading problems. Moreover, it is \nnot reasonable to adopt identity mapping for all layer parameters. In this paper, we first establish a simplified \nResNet that is similar to the ResNet in principle, and deduce the back propagation of the networks. \n \nHeechul Jung et al.,(2017), proposed work on" ResNet-Based Vehicle Classification and Localization in \nTraffic Surveillance Systems " In this paper, we present ResNet -based vehicle classification and \nlocalization methods using real traffic surveillance recordings. We utilize a MIOvision traffic dataset, which \ncomprises 11 categories including a variety of vehicles, such as bicycle, bus, car, motorcycle, and so on.  \n \n Melike Sardogan et al.,( 2018), proposed work on " Plant Leaf Dise ase Detection and Classification \nBased on CNN "  early detection of diseases is important in agriculture for an efficient crop yield.  bacterial \nspot, late blight, septoria leaf spot and yellow curved leaf diseases affect the crop quality of tomatoes. \nAutomatic methods for classification of plant diseases also help taking action after detecting the symptoms \nof leaf diseases. paper presents a Convolutional Neural Network (CNN) model and Learning Vector \nQuantization (LVQ) algorithm base method for tomato leaf  disease detection and classification.  dataset \ncontains 500 images of tomato leaves with four symptoms of diseases. We have modeled a CNN for \nautomatic feature extraction and classification. Color information is actively used for plant leaf disease \nresearches. In our model, the filters are applied to three channels based on RGB components. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 7}, page_content='PLANT LEAF DISEASE DETECTION \nPage 6 of 17 \n \n \nCHAPTER 3: DETAILED DESIGN  \n \n3.1: ARCHITECTURE DIAGRAM: \n \n \n \n  Architecture Diagram \nDescription: \n1.Data set: We have collected a Data set having different plants and its variety of diseases for each \nplant along with the healthy leaf images \n2.Splitting Data: splitting of collected Data set into 80% and 20% as training Dataset and Validation \ndata set respectively.  \n3.ResNet Architecture: In ResNets, unlike in traditiona l neural networks, each layer feeds into the \nnext layer, we use a network with residual blocks, each layer feeds into the next layer and directly \ninto the layers about 2 –3 hops away, to avoid over -fitting (a situation when validation loss stop \ndecreasing at a point and then keeps increasing while training loss still decreases). This also helps in \npreventing vanishing gradient problem and allow us to train deep neural networks. \n4.Train/Validate Model : Training Data set is used to train the model, and Validation Data set is \nused to check how much the model is learned from training data set and to finding the accuracy of \npredicting the input image. \n5.input image is converted into array and passed to the model having resnet architecture which has \nbeen trained by the data set and get predictions from the model, picks index with highest probability \nand prints the class label  \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 8}, page_content='PLANT LEAF DISEASE DETECTION \nPage 7 of 17 \n \n \n3.2: ResNet ARCHITECTURE: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n                                      \n \n     \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n            \n                              \n \n                       ResNet Architecture \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 9}, page_content='PLANT LEAF DISEASE DETECTION \nPage 8 of 17 \n \n \nDescription: \nSince neural networks are good function approximators, they should be able to easily solve the identify \nfunction, where the output of a function becomes the input itself. \nF(x)=x  \n \nFollowing the same logic, if we bypass the input to the first layer of the model to be the output of the \nlast layer of the model, the network should be able to predict whatever function it was learning before with \nthe input added to it. \n   F(x) + x = h(x) \nOne of the problems ResNets solve is the famous known  vanishing gradient. This is because when \nthe network is too deep, the gradients from where the loss function is calculated easily shrink to zero after \nseveral applications of the chain rule. This result on the weights never updating its values  and therefore, no \nlearning is being performed. \nWith ResNets, the gradients can flow directly through the skip connections backwards from later \nlayers to initial filters. \n \n3.1: USECASE DIAGRAM: \n                                \n                Use Case -Diagram \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 10}, page_content='PLANT LEAF DISEASE DETECTION \nPage 9 of 17 \n \n \nCHAPTER 4: PROJECT SPECIFIC REQUIREMENTS \n \n4.1 -Functional Requirements : \n\uf0b7 User Level: \n1. User shall be able to input test data (image). \n2. User shall be able to perform analysis after the results. \n3. User shall be able to train the data if required. \n4. User shall be able to view the result \n \n\uf0b7 System Level: \n1. System should provide option to input the test image. \n2. System should provide option to display results. \n3. System should accept the input. \n4. System should predict the output. \n5. System should display result.  \n6. System should provide the option for user’s to retrain. \n \n4.2-Nonfunctional Requirements:   \n  1.Portability: The program should be platform Independent \n  2.Usability: The system should be easy to deal and simple to understand \n  3.Speed and Response: Execution of the operations must be in seconds \n  4.Flexibility: The system should be easy to modify \n5.Accuracy and Precision : The system should perform its process with accuracy and                     \nprecision to avoid problems \n \n4.3- Software and Hardware Requirements: \n1. A computer with at least 2 virtual core processor, at least 4 GB RAM,  ideally having a dedicated        \nGPU. \n \n2. Any of these Python IDLE -Jupiter Notebook, Pycharm with  Pre-installed necessary libraries  and \nmodules.  \n \n3. Google Colab to design these models. \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 11}, page_content='PLANT LEAF DISEASE DETECTION \nPage 10 of 17 \n \n \nCHAPTER 5: IMPLEMENTATION \n \n5.1 INCORPORATED PACKAGE: \n 5.1.1: Pytorch : \n-PyTorch is a python package that provides two high-level features: - \nTensor computation (like numpy) with strong GPU acceleration - Deep \nNeural Networks built on a tape-based autograd system \nYou can reuse your favorite python packages such as numpy, scipy and \nCython to extend PyTorch when needed. \n-Usually one uses PyTorch either as: \n                     - A replacement for numpy to use the power of GPUs. \n                     - a deep learning research platform that provides maximum flexibility \n                        and speed \n-It provides a wide variety of tensor routines to accelerate and fit your \nscientific computation needs such as slicing, indexing, math operations, \nlinear algebra, reductions. And they are fast \n 5.1.2:  torchsummary: \n- Torch-summary provides information complementary to what is provided by print(your \nmodel)  in PyTorch, similar to Tensorflow\'s model.summary() API to view the visualization \nof the model, which is helpful while debugging your network. In this project, we implement a \nsimilar functionality in PyTorch and create a clean, simple interface to use in your projects. \n 5.1.3:  Matplotlib.pyplot:  \n-Matplotlib is a plotting library for the Python programming language and its \nnumericalmathematics extension NumPy.  ere is also a procedural "pylab" interface based on \nastate machine (like OpenGL Matplotlib), designed to closely resemble that of MATLAB. \nPyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is \ndesigned to beas usable as MATLAB \n 5.1.4: torchvision: \n-The torchvision package consists of popular datasets, model architectures, and common \nimage transformations for computer vision. Used for transforming image into tensors,for \nworking with class and image. \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 12}, page_content='PLANT LEAF DISEASE DETECTION \nPage 11 of 17 \n \n \n \n     Importing modules \n \n5.2 Exploring the data:  \n \n \n \n \n5.3 Data preparation for training:  \n \n  \n \ntorchvision.datasets is a class which helps in loading all common and famous datasets. It also helps \nin loading custom datasets. I have used subclass torchvision.datasets. ImageFolder which helps in loading \nthe image data when the data is arranged in this way: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 13}, page_content='PLANT LEAF DISEASE DETECTION \nPage 12 of 17 \n \n \nroot/dog/xxx.png \nroot/dog/xxy.png \nroot/dog/xxz.png \n \nroot/cat/123.png \nroot/cat/nsdf3.png \nroot/cat/asd932_.png \n \n \n-Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural \nnetworks works quite good with normalized data. The entire array of pixel values is converted to \ntorch tensor and then divided by 255.   \n \n5.4: Modelling: \nIt is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized \nfor general purpose and GPUs are optimized for training deep learning models as they can process multiple \ncomputations simultaneously. They have a large number of cores, which allows for better computation of \nmultiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of \ndata — this makes a GPU’s memory bandwidth most suitable. To seamlessly use a GPU, if one is available, \nwe define a couple of helper functions (get_default_device & to_device) and a helper \nclass DeviceDataLoader to move our model & data to the GPU as required \n \n5.5 Building Architecture: \n \nWe are going to use   ResNet,  one of the major breakthrough in computer vision since they were introduced \nin 2015. \nIn ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with \nresidual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to \navoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while \ntraining loss still decreases). This also helps in preventing vanishing gradient problem and allow us to train \ndeep neural networks. Here is a simple residual block: \n \n \n '), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 14}, page_content='PLANT LEAF DISEASE DETECTION \nPage 13 of 17 \n \n \n \n5.6: Building Final architecture of our model: \n \n \n \n  \n5.7: Training the Model: \n -Training \n -Gradient Clipping \n -Recording and updating learning rate \n -Validation \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 15}, page_content='PLANT LEAF DISEASE DETECTION \nPage 14 of 17 \n \n \nCHAPTER 6: RESULTS \n \n 6.1:Accuracy vs No of epochs: \n \n \n \n6.2:Loss vs No. of epochs \n \n                \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 16}, page_content='PLANT LEAF DISEASE DETECTION \nPage 15 of 17 \n \n \n6.3:Accuracy: \n       \n \n \n \n \n6.3: Images of first batch of Training: \n \n \n \n \n \n \n \n \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 17}, page_content='PLANT LEAF DISEASE DETECTION \nPage 16 of 17 \n \n \n6.4:  Output: \n \n \n \n \n'), Document(metadata={'source': 'C:\\Users\\tejas\\Desktop\\myDoc\\Major project-report.pdf', 'page': 18}, page_content='PLANT LEAF DISEASE DETECTION \nPage 17 of 17 \n \n \nREFERENCES \n \n[1]. https://towardsdatascience.com/understanding-and-visualizing-resnets-  \n[2]. https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035 \n [3]. https://jovian.ai/aakashns/05b-cifar10-resnet \n[4]. https://pytorch.org/ \n[5]. Singh, D., Jain, N., Jain, P., Kayal, P., Kumawat, S., and Batra, N. (2020, January 5–7). PlantDoc: A \ndataset for visual plant disease detection. Proceedings of the 7th ACM IKDD CoDS and 25th COMAD, \nHyderabad, India. \n https://doi.org/10.1145/3371158.3371196 \n [6]. BhangeManisha et al. \nSmart farming: Pomegranate disease detection using image processing \nProcedia Comput. Sci. \n(2015) \n \n[7]. LiuWeibo et al. \nA survey of deep neural network architectures and their applications \nNeurocomputing \n(2017) \n \n[8]. HarakannanavarSunil S. et al. \nPlant leaf disease detection using computer vision and machine learning algorithms \nGlob. Transitions Proc. \n(2022) \n \n')]
Similarity between query and document 0: 0.738794830914996
Similarity between query and document 0: 0.738794830914996
Similarity between query and document 0: 0.738794830914996
Similarity between query and document 1: 0.7283805641769692
Similarity between query and document 1: 0.7283805641769692
Similarity between query and document 1: 0.7283805641769692
Similarity between query and document 2: 0.7299076910258404
Similarity between query and document 2: 0.7299076910258404
Similarity between query and document 2: 0.7299076910258404
Similarity between query and document 3: 0.7970547841256435
Similarity between query and document 3: 0.7970547841256435
Similarity between query and document 3: 0.7970547841256435
Similarity between query and document 4: 0.7118431252280073
Similarity between query and document 4: 0.7118431252280073
Similarity between query and document 4: 0.7118431252280073
Similarity between query and document 5: 0.7015159172515872
Similarity between query and document 5: 0.7015159172515872
Similarity between query and document 5: 0.7015159172515872
Similarity between query and document 6: 0.704759064938254
Similarity between query and document 6: 0.704759064938254
Similarity between query and document 6: 0.704759064938254
Similarity between query and document 10: 0.7003578748322156
Similarity between query and document 10: 0.7003578748322156
Similarity between query and document 10: 0.7003578748322156
Similarity between query and document 11: 0.6878721900925792
Similarity between query and document 11: 0.6878721900925792
Similarity between query and document 11: 0.6878721900925792
Similarity between query and document 12: 0.705250511141571
Similarity between query and document 12: 0.705250511141571
Similarity between query and document 12: 0.705250511141571
Similarity between query and document 13: 0.6870953108171836
Similarity between query and document 13: 0.6870953108171836
Similarity between query and document 13: 0.6870953108171836
Similarity between query and document 18: 0.7093452126655966
Similarity between query and document 18: 0.7093452126655966
Similarity between query and document 18: 0.7093452126655966
Similarity between query and document 19: 0.6879912361793814
Similarity between query and document 19: 0.6879912361793814
Similarity between query and document 19: 0.6879912361793814
Similarity between query and document 20: 0.7043893775548762
Similarity between query and document 20: 0.7043893775548762
Similarity between query and document 20: 0.7043893775548762
Similarity between query and document 27: 0.7672591836206646
Similarity between query and document 27: 0.7672591836206646
Similarity between query and document 27: 0.7672591836206646
Similarity between query and document 29: 0.7184451674189832
Similarity between query and document 29: 0.7184451674189832
Similarity between query and document 29: 0.7184451674189832
Similarity between query and document 39: 0.6997143192577967
Similarity between query and document 39: 0.6997143192577967
Similarity between query and document 39: 0.6997143192577967
Similarity between query and document 41: 0.6923482908861842
Similarity between query and document 41: 0.6923482908861842
Similarity between query and document 41: 0.6923482908861842
Similarity between query and document 8: 0.8145065468766138
Similarity between query and document 8: 0.8145065468766138
Similarity between query and document 8: 0.8145065468766138
Similarity between query and document 14: 0.699507517575833
Similarity between query and document 14: 0.699507517575833
Similarity between query and document 14: 0.699507517575833
Similarity between query and document 15: 0.6656153068650715
Similarity between query and document 15: 0.6656153068650715
Similarity between query and document 15: 0.6656153068650715
Similarity between query and document 16: 0.6930330717842998
Similarity between query and document 16: 0.6930330717842998
Similarity between query and document 16: 0.6930330717842998
Similarity between query and document 17: 0.6930386865704673
Similarity between query and document 17: 0.6930386865704673
Similarity between query and document 17: 0.6930386865704673
Similarity between query and document 22: 0.6825550952647861
Similarity between query and document 22: 0.6825550952647861
Similarity between query and document 22: 0.6825550952647861
Similarity between query and document 23: 0.6969013794600043
Similarity between query and document 23: 0.6969013794600043
Similarity between query and document 23: 0.6969013794600043
Similarity between query and document 24: 0.6910516249816243
Similarity between query and document 24: 0.6910516249816243
Similarity between query and document 24: 0.6910516249816243
Similarity between query and document 34: 0.6733457180819568
Similarity between query and document 34: 0.6733457180819568
Similarity between query and document 34: 0.6733457180819568
Similarity between query and document 37: 0.6984299003936549
Similarity between query and document 37: 0.6984299003936549
Similarity between query and document 37: 0.6984299003936549
Similarity between query and document 38: 0.6802820634197568
Similarity between query and document 38: 0.6802820634197568
Similarity between query and document 38: 0.6802820634197568
Similarity between query and document 40: 0.7019155297484577
Similarity between query and document 40: 0.7019155297484577
Similarity between query and document 40: 0.7019155297484577
Similarity between query and document 36: 0.6839805374087112
Similarity between query and document 36: 0.6839805374087112
Similarity between query and document 36: 0.6839805374087112
Similarity between query and document 7: 0.7711637474076771
Similarity between query and document 7: 0.7711637474076771
Similarity between query and document 7: 0.7711637474076771
Similarity between query and document 9: 0.7398870889708926
Similarity between query and document 9: 0.7398870889708926
Similarity between query and document 9: 0.7398870889708926
Similarity between query and document 28: 0.7707492407874111
Similarity between query and document 28: 0.7707492407874111
Similarity between query and document 28: 0.7707492407874111
Similarity between query and document 25: 0.6751583371718848
Similarity between query and document 25: 0.6751583371718848
Similarity between query and document 25: 0.6751583371718848
Similarity between query and document 26: 0.6678119086678739
Similarity between query and document 26: 0.6678119086678739
Similarity between query and document 26: 0.6678119086678739
Similarity between query and document 21: 0.7253859321357389
Similarity between query and document 21: 0.7253859321357389
Similarity between query and document 21: 0.7253859321357389
Similarity between query and document 35: 0.6763151617083303
Similarity between query and document 35: 0.6763151617083303
Similarity between query and document 35: 0.6763151617083303
Similarity between query and document 30: 0.686806500764452
Similarity between query and document 30: 0.686806500764452
Similarity between query and document 30: 0.686806500764452
Similarity between query and document 31: 0.7392773247708659
Similarity between query and document 31: 0.7392773247708659
Similarity between query and document 31: 0.7392773247708659
Similarity between query and document 33: 0.6743266296665984
Similarity between query and document 33: 0.6743266296665984
Similarity between query and document 33: 0.6743266296665984
Similarity between query and document 32: 0.7504503971609473
Similarity between query and document 32: 0.7504503971609473
Similarity between query and document 32: 0.7504503971609473
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Similarity between query and document 0: 0.736996366449996
Similarity between query and document 0: 0.736996366449996
Similarity between query and document 0: 0.736996366449996
Similarity between query and document 0: 0.736996366449996
Similarity between query and document 1: 0.7270230855094745
Similarity between query and document 1: 0.7270230855094745
Similarity between query and document 1: 0.7270230855094745
Similarity between query and document 1: 0.7270230855094745
Similarity between query and document 2: 0.728897927638681
Similarity between query and document 2: 0.728897927638681
Similarity between query and document 2: 0.728897927638681
Similarity between query and document 2: 0.728897927638681
Similarity between query and document 3: 0.7926804776446851
Similarity between query and document 3: 0.7926804776446851
Similarity between query and document 3: 0.7926804776446851
Similarity between query and document 3: 0.7926804776446851
Similarity between query and document 4: 0.70622852637982
Similarity between query and document 4: 0.70622852637982
Similarity between query and document 4: 0.70622852637982
Similarity between query and document 4: 0.70622852637982
Similarity between query and document 5: 0.7037428311610747
Similarity between query and document 5: 0.7037428311610747
Similarity between query and document 5: 0.7037428311610747
Similarity between query and document 5: 0.7037428311610747
Similarity between query and document 6: 0.7031402851825965
Similarity between query and document 6: 0.7031402851825965
Similarity between query and document 6: 0.7031402851825965
Similarity between query and document 6: 0.7031402851825965
Similarity between query and document 10: 0.6978688135958875
Similarity between query and document 10: 0.6978688135958875
Similarity between query and document 10: 0.6978688135958875
Similarity between query and document 10: 0.6978688135958875
Similarity between query and document 11: 0.6906321090126566
Similarity between query and document 11: 0.6906321090126566
Similarity between query and document 11: 0.6906321090126566
Similarity between query and document 11: 0.6906321090126566
Similarity between query and document 12: 0.710756566439037
Similarity between query and document 12: 0.710756566439037
Similarity between query and document 12: 0.710756566439037
Similarity between query and document 12: 0.710756566439037
Similarity between query and document 13: 0.6896399531454678
Similarity between query and document 13: 0.6896399531454678
Similarity between query and document 13: 0.6896399531454678
Similarity between query and document 13: 0.6896399531454678
Similarity between query and document 18: 0.7078734083669601
Similarity between query and document 18: 0.7078734083669601
Similarity between query and document 18: 0.7078734083669601
Similarity between query and document 18: 0.7078734083669601
Similarity between query and document 19: 0.6849934784864876
Similarity between query and document 19: 0.6849934784864876
Similarity between query and document 19: 0.6849934784864876
Similarity between query and document 19: 0.6849934784864876
Similarity between query and document 20: 0.7091301572446241
Similarity between query and document 20: 0.7091301572446241
Similarity between query and document 20: 0.7091301572446241
Similarity between query and document 20: 0.7091301572446241
Similarity between query and document 27: 0.7685639885466252
Similarity between query and document 27: 0.7685639885466252
Similarity between query and document 27: 0.7685639885466252
Similarity between query and document 27: 0.7685639885466252
Similarity between query and document 29: 0.7235902128759565
Similarity between query and document 29: 0.7235902128759565
Similarity between query and document 29: 0.7235902128759565
Similarity between query and document 29: 0.7235902128759565
Similarity between query and document 39: 0.6980413812738531
Similarity between query and document 39: 0.6980413812738531
Similarity between query and document 39: 0.6980413812738531
Similarity between query and document 39: 0.6980413812738531
Similarity between query and document 41: 0.6897005793906754
Similarity between query and document 41: 0.6897005793906754
Similarity between query and document 41: 0.6897005793906754
Similarity between query and document 41: 0.6897005793906754
Similarity between query and document 8: 0.8182821560286531
Similarity between query and document 8: 0.8182821560286531
Similarity between query and document 8: 0.8182821560286531
Similarity between query and document 8: 0.8182821560286531
Similarity between query and document 14: 0.7031596651933608
Similarity between query and document 14: 0.7031596651933608
Similarity between query and document 14: 0.7031596651933608
Similarity between query and document 14: 0.7031596651933608
Similarity between query and document 15: 0.6747155999233139
Similarity between query and document 15: 0.6747155999233139
Similarity between query and document 15: 0.6747155999233139
Similarity between query and document 15: 0.6747155999233139
Similarity between query and document 16: 0.6910770374677933
Similarity between query and document 16: 0.6910770374677933
Similarity between query and document 16: 0.6910770374677933
Similarity between query and document 16: 0.6910770374677933
Similarity between query and document 17: 0.6929031789070119
Similarity between query and document 17: 0.6929031789070119
Similarity between query and document 17: 0.6929031789070119
Similarity between query and document 17: 0.6929031789070119
Similarity between query and document 22: 0.6909250188386687
Similarity between query and document 22: 0.6909250188386687
Similarity between query and document 22: 0.6909250188386687
Similarity between query and document 22: 0.6909250188386687
Similarity between query and document 23: 0.6966755048688646
Similarity between query and document 23: 0.6966755048688646
Similarity between query and document 23: 0.6966755048688646
Similarity between query and document 23: 0.6966755048688646
Similarity between query and document 24: 0.6910909579675517
Similarity between query and document 24: 0.6910909579675517
Similarity between query and document 24: 0.6910909579675517
Similarity between query and document 24: 0.6910909579675517
Similarity between query and document 34: 0.6710955191382011
Similarity between query and document 34: 0.6710955191382011
Similarity between query and document 34: 0.6710955191382011
Similarity between query and document 34: 0.6710955191382011
Similarity between query and document 37: 0.6933590704321484
Similarity between query and document 37: 0.6933590704321484
Similarity between query and document 37: 0.6933590704321484
Similarity between query and document 37: 0.6933590704321484
Similarity between query and document 38: 0.687856372744309
Similarity between query and document 38: 0.687856372744309
Similarity between query and document 38: 0.687856372744309
Similarity between query and document 38: 0.687856372744309
Similarity between query and document 40: 0.7000597711907688
Similarity between query and document 40: 0.7000597711907688
Similarity between query and document 40: 0.7000597711907688
Similarity between query and document 40: 0.7000597711907688
Similarity between query and document 36: 0.6923885939096024
Similarity between query and document 36: 0.6923885939096024
Similarity between query and document 36: 0.6923885939096024
Similarity between query and document 36: 0.6923885939096024
Similarity between query and document 7: 0.7718219437871643
Similarity between query and document 7: 0.7718219437871643
Similarity between query and document 7: 0.7718219437871643
Similarity between query and document 7: 0.7718219437871643
Similarity between query and document 9: 0.7375973647579595
Similarity between query and document 9: 0.7375973647579595
Similarity between query and document 9: 0.7375973647579595
Similarity between query and document 9: 0.7375973647579595
Similarity between query and document 28: 0.7665081222898564
Similarity between query and document 28: 0.7665081222898564
Similarity between query and document 28: 0.7665081222898564
Similarity between query and document 28: 0.7665081222898564
Similarity between query and document 25: 0.6712599465031863
Similarity between query and document 25: 0.6712599465031863
Similarity between query and document 25: 0.6712599465031863
Similarity between query and document 25: 0.6712599465031863
Similarity between query and document 26: 0.6708110631065496
Similarity between query and document 26: 0.6708110631065496
Similarity between query and document 26: 0.6708110631065496
Similarity between query and document 26: 0.6708110631065496
Similarity between query and document 21: 0.7249585550389434
Similarity between query and document 21: 0.7249585550389434
Similarity between query and document 21: 0.7249585550389434
Similarity between query and document 21: 0.7249585550389434
Similarity between query and document 35: 0.6716141841509625
Similarity between query and document 35: 0.6716141841509625
Similarity between query and document 35: 0.6716141841509625
Similarity between query and document 35: 0.6716141841509625
Similarity between query and document 30: 0.6895333815139936
Similarity between query and document 30: 0.6895333815139936
Similarity between query and document 30: 0.6895333815139936
Similarity between query and document 30: 0.6895333815139936
Similarity between query and document 31: 0.7445911984488691
Similarity between query and document 31: 0.7445911984488691
Similarity between query and document 31: 0.7445911984488691
Similarity between query and document 31: 0.7445911984488691
Similarity between query and document 33: 0.6737877629483642
Similarity between query and document 33: 0.6737877629483642
Similarity between query and document 33: 0.6737877629483642
Similarity between query and document 33: 0.6737877629483642
Similarity between query and document 32: 0.7485890564225004
Similarity between query and document 32: 0.7485890564225004
Similarity between query and document 32: 0.7485890564225004
Similarity between query and document 32: 0.7485890564225004
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
Found 42 documents with similarity > 0.6
